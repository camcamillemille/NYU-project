{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import MultipleLocator, FuncFormatter\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances, silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler,normalize\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score, pairwise_distances\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)  # None = no limit for when i do df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "##### Preprocessing\n",
    "Here are the following functions defined:\n",
    "1. 'preprocess_dataframe'\n",
    "2. 'filter_reads_per_gene_middle_bin_name'\n",
    "3. 'bin_then_matrix'\n",
    "4. 'process_into_matrix'\n",
    "5. 'handling_NaN'\n",
    "6. 'preprocess_long_for_plot'\n",
    "7. 'plot_reads_long'\n",
    "8. 'get_genes_list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin_scatter(\n",
    "    results_df,\n",
    "    metrics=('silhouette', 'calinski_harabasz', 'davies_bouldin',\n",
    "             'leiden_quality', 'modularity', 'n_clusters')\n",
    "):\n",
    "    \"\"\"\n",
    "    Violin + scatter (strip) plots comparing pipelines for each metric across genes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results_df : pandas.DataFrame\n",
    "        Output from run_pipelines_on_genes().\n",
    "    metrics : tuple of str\n",
    "        Metrics to visualize.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    figs : dict\n",
    "        Dictionary of matplotlib Figures, keyed by metric name.\n",
    "    \"\"\"\n",
    "    # Melt to long format\n",
    "    df_long = results_df.melt(\n",
    "        id_vars=['gene', 'pipeline'],\n",
    "        value_vars=[m for m in metrics if m in results_df.columns],\n",
    "        var_name='metric',\n",
    "        value_name='value'\n",
    "    )\n",
    "\n",
    "    # Drop missing or failed results\n",
    "    df_long = df_long.dropna(subset=['value'])\n",
    "\n",
    "    # Plot one figure per metric\n",
    "    figs = {}\n",
    "    for metric_name, sub in df_long.groupby('metric'):\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        ax = sns.violinplot(\n",
    "            data=sub,\n",
    "            x='pipeline',\n",
    "            y='value',\n",
    "            inner=None,\n",
    "            cut=0\n",
    "        )\n",
    "        sns.stripplot(\n",
    "            data=sub,\n",
    "            x='pipeline',\n",
    "            y='value',\n",
    "            color='k',\n",
    "            size=4,\n",
    "            alpha=0.6,\n",
    "            jitter=0.2\n",
    "        )\n",
    "        ax.set_title(f'Comparison by {metric_name}')\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel(metric_name)\n",
    "        ax.grid(axis='y', linestyle='--')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        figs[metric_name] = ax.get_figure()\n",
    "        \n",
    "\n",
    "    return figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare_pipelines_grid(\n",
    "    results_df: pd.DataFrame,\n",
    "    pipelines_order=('pca_euclidean', 'cosine_no_pca'),\n",
    "    metrics=('silhouette', 'calinski_harabasz', 'davies_bouldin',\n",
    "             'leiden_quality', 'modularity', 'n_clusters'),\n",
    "    kind='violin',                # 'violin' or 'box'\n",
    "    show_points=True,\n",
    "    connect_pairs=True,           # draw line per gene connecting the two pipelines\n",
    "    figsize=None,\n",
    "    point_kwargs=None,\n",
    "    violin_kwargs=None,\n",
    "    box_kwargs=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Make ONE figure with one subplot per metric; within each subplot, \n",
    "    show pipelines side-by-side.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results_df : pd.DataFrame\n",
    "        Must contain columns ['gene', 'pipeline', <metrics...>].\n",
    "    pipelines_order : tuple\n",
    "        Order of pipelines to display.\n",
    "    metrics : tuple\n",
    "        Which metrics to plot.\n",
    "    kind : {'violin', 'box'}\n",
    "        Plot type for distributions.\n",
    "    show_points : bool\n",
    "        Whether to overlay individual gene points.\n",
    "    connect_pairs : bool\n",
    "        Whether to connect paired genes across pipelines.\n",
    "    figsize : tuple or None\n",
    "        Figure size; computed automatically if None.\n",
    "    *_kwargs : dict or None\n",
    "        Style options passed to Seaborn plotting functions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig, axes : matplotlib Figure and Axes objects\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Filter metrics and pipelines ---\n",
    "    metrics = [m for m in metrics if m in results_df.columns]\n",
    "    if not metrics:\n",
    "        raise ValueError(\"No requested metrics found in results_df.\")\n",
    "\n",
    "    df = results_df.copy()\n",
    "    df = df[df['pipeline'].isin(pipelines_order)]\n",
    "    if df.empty:\n",
    "        raise ValueError(\"results_df has no rows for the requested pipelines_order.\")\n",
    "\n",
    "    # Ensure pipelines are ordered consistently\n",
    "    df['pipeline'] = pd.Categorical(df['pipeline'],\n",
    "                                    categories=list(pipelines_order),\n",
    "                                    ordered=True)\n",
    "\n",
    "    # --- Melt to long format ---\n",
    "    df_long = (\n",
    "        df.melt(\n",
    "            id_vars=['gene', 'pipeline'],\n",
    "            value_vars=metrics,\n",
    "            var_name='metric',\n",
    "            value_name='value'\n",
    "        )\n",
    "        .dropna(subset=['value'])\n",
    "    )\n",
    "\n",
    "    # --- Set up figure ---\n",
    "    n_cols = len(metrics)\n",
    "    if figsize is None:\n",
    "        figsize = (3.2 * n_cols, 4.2)  # scale width by number of metrics\n",
    "\n",
    "    fig, axes = plt.subplots(1, n_cols, figsize=figsize, sharey=False)\n",
    "    if n_cols == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # --- Default style dictionaries ---\n",
    "    if point_kwargs is None:\n",
    "        point_kwargs = dict(color='k', s=18, alpha=0.7)\n",
    "    if violin_kwargs is None:\n",
    "        violin_kwargs = dict(inner=None, cut=0, linewidth=0)\n",
    "    if box_kwargs is None:\n",
    "        box_kwargs = dict(fliersize=0, linewidth=1.2)\n",
    "\n",
    "    # --- Color palette ---\n",
    "    palette = sns.color_palette('Set2', n_colors=len(pipelines_order))\n",
    "    pipeline_colors = dict(zip(pipelines_order, palette))\n",
    "\n",
    "    # --- Plot each metric ---\n",
    "    for ax, metric_name in zip(axes, metrics):\n",
    "        sub = df_long[df_long['metric'] == metric_name]\n",
    "\n",
    "        # Main distribution plot\n",
    "        if kind == 'violin':\n",
    "            sns.violinplot(\n",
    "                data=sub,\n",
    "                x='pipeline', y='value',\n",
    "                order=list(pipelines_order),\n",
    "                palette=pipeline_colors,\n",
    "                ax=ax, **violin_kwargs\n",
    "            )\n",
    "        elif kind == 'box':\n",
    "            sns.boxplot(\n",
    "                data=sub,\n",
    "                x='pipeline', y='value',\n",
    "                order=list(pipelines_order),\n",
    "                palette=pipeline_colors,\n",
    "                ax=ax, **box_kwargs\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"kind must be 'violin' or 'box'\")\n",
    "\n",
    "        # Overlay points\n",
    "        if show_points:\n",
    "            sns.stripplot(\n",
    "                data=sub,\n",
    "                x='pipeline', y='value',\n",
    "                order=list(pipelines_order),\n",
    "                dodge=False, jitter=0.15,\n",
    "                color='k', size=4, alpha=0.6, ax=ax\n",
    "            )\n",
    "\n",
    "        # Connect paired points (same gene across pipelines)\n",
    "        if connect_pairs and len(pipelines_order) == 2:\n",
    "            p0, p1 = pipelines_order\n",
    "\n",
    "            # Pivot to wide format (gene × pipeline)\n",
    "            wide = sub.pivot_table(index='gene', columns='pipeline',\n",
    "                                   values='value', aggfunc='first')\n",
    "            wide = wide.dropna(subset=[p0, p1], how='any')\n",
    "\n",
    "            # Draw connecting lines\n",
    "            for _, row in wide.iterrows():\n",
    "                ax.plot([0, 1], [row[p0], row[p1]],\n",
    "                        color='gray', alpha=0.35, linewidth=1)\n",
    "\n",
    "        # Axis formatting\n",
    "        ax.set_title(metric_name.replace('_', ' ').title())\n",
    "        ax.set_xlabel('')\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.25)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouettes_multi(\n",
    "    X_space,\n",
    "    clusters,\n",
    "    metric_main='cosine',\n",
    "    extra_metrics=('correlation', 'euclidean')\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute silhouette scores for multiple distance metrics.\n",
    "\n",
    "    Args:\n",
    "        X_space (array-like): Feature matrix (n_samples x n_features).\n",
    "        clusters (array-like): Cluster labels.\n",
    "        metric_main (str): Primary metric to evaluate (default: 'cosine').\n",
    "        extra_metrics (tuple): Additional metrics to test (default: ('correlation', 'euclidean')).\n",
    "\n",
    "    Returns:\n",
    "        dict: Silhouette scores for each metric, using direct or precomputed distances.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Main metric\n",
    "    try:\n",
    "        results[f'silhouette_{metric_main}'] = silhouette_score(\n",
    "            X_space, clusters, metric=metric_main\n",
    "        )\n",
    "    except Exception:\n",
    "        D = pairwise_distances(X_space, metric=metric_main)\n",
    "        results[f'silhouette_{metric_main}'] = silhouette_score(\n",
    "            D, clusters, metric='precomputed'\n",
    "        )\n",
    "\n",
    "    # Extra metrics\n",
    "    for m in extra_metrics:\n",
    "        try:\n",
    "            results[f'silhouette_{m}'] = silhouette_score(\n",
    "                X_space, clusters, metric=m\n",
    "            )\n",
    "        except Exception:\n",
    "            D = pairwise_distances(X_space, metric=m)\n",
    "            results[f'silhouette_{m}'] = silhouette_score(\n",
    "                D, clusters, metric='precomputed'\n",
    "            )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1) Multi-metric silhouette\n",
    "# -----------------------------\n",
    "def silhouettes_multi(\n",
    "    X_space,\n",
    "    clusters,\n",
    "    metric_main: str = 'cosine',\n",
    "    extra_metrics: tuple = ('correlation', 'euclidean')\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Compute silhouette scores for multiple distance metrics.\n",
    "    Returns a dict with keys like 'silhouette_cosine', 'silhouette_correlation', etc.\n",
    "    Falls back to precomputed pairwise distances when needed.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    def _one(metric_name: str):\n",
    "        try:\n",
    "            return float(silhouette_score(X_space, clusters, metric=metric_name))\n",
    "        except Exception:\n",
    "            D = pairwise_distances(X_space, metric=metric_name)\n",
    "            return float(silhouette_score(D, clusters, metric='precomputed'))\n",
    "\n",
    "    # main\n",
    "    results[f'silhouette_{metric_main}'] = _one(metric_main)\n",
    "\n",
    "    # extras\n",
    "    for m in extra_metrics:\n",
    "        results[f'silhouette_{m}'] = _one(m)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2) Integrate multi-silhouette into your result\n",
    "# ----------------------------------------------\n",
    "def add_silhouette_columns(\n",
    "    results_df: pd.DataFrame,\n",
    "    embed_dict: dict\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add multiple silhouette columns to results_df.\n",
    "    - results_df must contain 'gene' and 'pipeline' columns (rows are runs).\n",
    "    - embed_dict maps (gene, pipeline) -> (X_space, clusters, metric_main) used for the run.\n",
    "      Example:\n",
    "          embed_dict[(gene, pipeline)] = {\n",
    "              'X': X_pca,\n",
    "              'labels': clusters,\n",
    "              'metric': metric   # the distance metric used in the run (e.g., 'cosine' or 'euclidean')\n",
    "          }\n",
    "    Returns a new DataFrame with additional 'silhouette_*' columns.\n",
    "    \"\"\"\n",
    "    out = results_df.copy()\n",
    "    # initialize silhouette columns if they don't exist yet\n",
    "    sil_cols_all = set([c for c in out.columns if c.startswith('silhouette_')])\n",
    "\n",
    "    rows = []\n",
    "    for idx, row in out.iterrows():\n",
    "        gene = row['gene']\n",
    "        pipeline = row['pipeline']\n",
    "        key = (gene, pipeline)\n",
    "        if key not in embed_dict:\n",
    "            rows.append({})\n",
    "            continue\n",
    "        X_space = embed_dict[key]['X']\n",
    "        labels = embed_dict[key]['labels']\n",
    "        metric_main = embed_dict[key].get('metric', 'cosine')\n",
    "\n",
    "        if len(np.unique(labels)) < 2 or X_space.shape[0] < 2:\n",
    "            rows.append({})\n",
    "            continue\n",
    "\n",
    "        sil_dict = silhouettes_multi(\n",
    "            X_space=X_space,\n",
    "            clusters=labels,\n",
    "            metric_main=metric_main,\n",
    "            extra_metrics=('correlation', 'euclidean')  # extend if you want more\n",
    "        )\n",
    "        sil_cols_all.update(sil_dict.keys())\n",
    "        rows.append(sil_dict)\n",
    "\n",
    "    # assign\n",
    "    sil_df = pd.DataFrame(rows, index=out.index)\n",
    "    out = pd.concat([out, sil_df], axis=1)\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3) Plotting: violin+scatter that auto-includes silhouettes\n",
    "# -------------------------------------------------------\n",
    "def plot_violin_scatter(\n",
    "    results_df: pd.DataFrame,\n",
    "    base_metrics: tuple = ('silhouette', 'calinski_harabasz', 'davies_bouldin',\n",
    "                           'leiden_quality', 'modularity', 'n_clusters'),\n",
    "):\n",
    "    \"\"\"\n",
    "    Violin + scatter (strip) plots comparing pipelines for each metric across genes.\n",
    "    Auto-includes any columns that start with 'silhouette_' (e.g., silhouette_cosine).\n",
    "    \"\"\"\n",
    "    # collect requested metrics + any silhouette_* columns present\n",
    "    sil_cols = [c for c in results_df.columns if c.startswith('silhouette_')]\n",
    "    metrics = [m for m in base_metrics if m in results_df.columns] + sil_cols\n",
    "    if not metrics:\n",
    "        raise ValueError(\"No requested metrics found in results_df.\")\n",
    "\n",
    "    # Melt to long format\n",
    "    df_long = results_df.melt(\n",
    "        id_vars=['gene', 'pipeline'],\n",
    "        value_vars=metrics,\n",
    "        var_name='metric',\n",
    "        value_name='value'\n",
    "    ).dropna(subset=['value'])\n",
    "\n",
    "    figs = {}\n",
    "    for metric_name, sub in df_long.groupby('metric'):\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        ax = sns.violinplot(\n",
    "            data=sub,\n",
    "            x='pipeline',\n",
    "            y='value',\n",
    "            inner=None,\n",
    "            cut=0\n",
    "        )\n",
    "        sns.stripplot(\n",
    "            data=sub,\n",
    "            x='pipeline',\n",
    "            y='value',\n",
    "            color='k',\n",
    "            size=4,\n",
    "            alpha=0.6,\n",
    "            jitter=0.2\n",
    "        )\n",
    "        ax.set_title(f'Comparison by {metric_name}')\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel(metric_name)\n",
    "        ax.grid(axis='y', linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        figs[metric_name] = ax.get_figure()\n",
    "    return figs\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4) One-figure grid: side-by-side pipelines and all silhouette columns\n",
    "# ----------------------------------------------------------------------\n",
    "def plot_compare_pipelines_grid(\n",
    "    results_df: pd.DataFrame,\n",
    "    pipelines_order=('pca_euclidean', 'cosine_no_pca'),\n",
    "    base_metrics=('calinski_harabasz', 'davies_bouldin',\n",
    "                  'leiden_quality', 'modularity', 'n_clusters'),\n",
    "    include_silhouettes: bool = True,\n",
    "    kind='violin',                # 'violin' or 'box'\n",
    "    show_points=True,\n",
    "    connect_pairs=True,           # draw line per gene connecting the two pipelines\n",
    "    figsize=None,\n",
    "    point_kwargs=None,\n",
    "    violin_kwargs=None,\n",
    "    box_kwargs=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Make ONE figure with one subplot per metric (auto-includes silhouette_* if present).\n",
    "    Within each subplot, show pipelines side-by-side.\n",
    "    \"\"\"\n",
    "    # gather metrics to plot\n",
    "    metrics = list(base_metrics)\n",
    "    if include_silhouettes:\n",
    "        sil_cols = [c for c in results_df.columns if c.startswith('silhouette_')]\n",
    "        metrics = metrics + sil_cols\n",
    "    metrics = [m for m in metrics if m in results_df.columns]\n",
    "    if not metrics:\n",
    "        raise ValueError(\"No requested metrics found in results_df.\")\n",
    "\n",
    "    df = results_df.copy()\n",
    "    df = df[df['pipeline'].isin(pipelines_order)]\n",
    "    if df.empty:\n",
    "        raise ValueError(\"results_df has no rows for the requested pipelines_order.\")\n",
    "\n",
    "    df['pipeline'] = pd.Categorical(df['pipeline'],\n",
    "                                    categories=list(pipelines_order),\n",
    "                                    ordered=True)\n",
    "\n",
    "    # Melt long\n",
    "    df_long = (\n",
    "        df.melt(\n",
    "            id_vars=['gene', 'pipeline'],\n",
    "            value_vars=metrics,\n",
    "            var_name='metric',\n",
    "            value_name='value'\n",
    "        )\n",
    "        .dropna(subset=['value'])\n",
    "    )\n",
    "\n",
    "    # Figure\n",
    "    n_cols = len(metrics)\n",
    "    if figsize is None:\n",
    "        figsize = (3.2 * n_cols, 4.2)\n",
    "    fig, axes = plt.subplots(1, n_cols, figsize=figsize, sharey=False)\n",
    "    if n_cols == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    if point_kwargs is None:\n",
    "        point_kwargs = dict(color='k', s=18, alpha=0.7)\n",
    "    if violin_kwargs is None:\n",
    "        violin_kwargs = dict(inner=None, cut=0, linewidth=0)\n",
    "    if box_kwargs is None:\n",
    "        box_kwargs = dict(fliersize=0, linewidth=1.2)\n",
    "\n",
    "    palette = sns.color_palette('Set2', n_colors=len(pipelines_order))\n",
    "    pipeline_colors = dict(zip(pipelines_order, palette))\n",
    "\n",
    "    for ax, metric_name in zip(axes, metrics):\n",
    "        sub = df_long[df_long['metric'] == metric_name]\n",
    "\n",
    "        if kind == 'violin':\n",
    "            sns.violinplot(\n",
    "                data=sub, x='pipeline', y='value',\n",
    "                order=list(pipelines_order),\n",
    "                palette=pipeline_colors, ax=ax, **violin_kwargs\n",
    "            )\n",
    "        elif kind == 'box':\n",
    "            sns.boxplot(\n",
    "                data=sub, x='pipeline', y='value',\n",
    "                order=list(pipelines_order),\n",
    "                palette=pipeline_colors, ax=ax, **box_kwargs\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"kind must be 'violin' or 'box'\")\n",
    "\n",
    "        if show_points:\n",
    "            sns.stripplot(\n",
    "                data=sub, x='pipeline', y='value',\n",
    "                order=list(pipelines_order),\n",
    "                dodge=False, jitter=0.15,\n",
    "                color='k', size=4, alpha=0.6, ax=ax\n",
    "            )\n",
    "\n",
    "        if connect_pairs and len(pipelines_order) == 2:\n",
    "            p0, p1 = pipelines_order\n",
    "            wide = sub.pivot_table(index='gene', columns='pipeline', values='value', aggfunc='first')\n",
    "            wide = wide.dropna(subset=[p0, p1], how='any')\n",
    "            for _, row in wide.iterrows():\n",
    "                ax.plot([0, 1], [row[p0], row[p1]], color='gray', alpha=0.35, linewidth=1)\n",
    "\n",
    "        ax.set_title(metric_name.replace('_', ' ').title())\n",
    "        ax.set_xlabel('')\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.25)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (unused) 3.1 ALTERNATE PIPELINE FOR CLUSTERING\n",
    "\n",
    "def filter_by_missingness(\n",
    "    df: pd.DataFrame,\n",
    "    min_bin_non_nan_frac: float = 0.2,  # keep bins (columns) seen in >= 20% of reads\n",
    "    min_read_non_nan_frac: float = 0.5  # keep reads (rows) with >= 50% bins observed\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Filter reads (rows) and bins (columns) based on missingness thresholds.\"\"\"\n",
    "    # rows = reads, columns = bins\n",
    "    if df.shape[0] < 2 or df.shape[1] < 2:\n",
    "        return df.copy()\n",
    "\n",
    "    keep_cols = df.notna().mean(axis=0) >= float(min_bin_non_nan_frac)\n",
    "    keep_rows = df.notna().mean(axis=1) >= float(min_read_non_nan_frac)\n",
    "    df_f = df.loc[keep_rows, keep_cols].copy()\n",
    "\n",
    "    return df_f\n",
    "\n",
    "\n",
    "def masked_pearson_correlation_matrix(\n",
    "    df: pd.DataFrame,\n",
    "    min_overlap: int = 30\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pairwise-complete Pearson correlation between reads (rows), computed only on shared\n",
    "    non-NaN bins, requiring at least min_overlap shared bins.\n",
    "\n",
    "    Returns an (N x N) DataFrame; entries with overlap < min_overlap are NaN.\n",
    "    \"\"\"\n",
    "    # df.T.corr computes correlation among rows of df\n",
    "    R = df.T.corr(min_periods=int(min_overlap))\n",
    "    return R\n",
    "\n",
    "\n",
    "def overlap_matrix(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Compute number of shared non-NaN bins for each read pair (N x N).\"\"\"\n",
    "    M = (~df.isna()).to_numpy(dtype=bool)  # shape (N, D)\n",
    "    O = M @ M.T\n",
    "    return O\n",
    "\n",
    "\n",
    "def build_masked_corr_knn_graph(\n",
    "    df: pd.DataFrame,\n",
    "    k: int = 15,\n",
    "    min_overlap: int = 30,\n",
    "    positive_only: bool = True,\n",
    "    shrink_c: float = 30.0,  # overlap-based shrink: w *= n / (n + shrink_c)\n",
    "    mutual: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a weighted kNN graph from masked Pearson correlations.\n",
    "\n",
    "    - df: rows = reads, columns = bins, values = methylation fractions (NaN allowed).\n",
    "\n",
    "    Returns:\n",
    "        igraph.Graph, weight list (in edge order), neighbor index list per node.\n",
    "    \"\"\"\n",
    "    N = df.shape[0]\n",
    "    if N < 2:\n",
    "        raise ValueError(\"Need at least 2 reads to build a graph.\")\n",
    "\n",
    "    # 1) Pairwise-complete correlation and overlap counts\n",
    "    R_df = masked_pearson_correlation_matrix(df, min_overlap=min_overlap)  # (N x N)\n",
    "    O = overlap_matrix(df)  # (N x N), shared bin counts\n",
    "\n",
    "    # 2) Convert to weights\n",
    "    R = R_df.to_numpy()\n",
    "    mask_sufficient = (O >= int(min_overlap))\n",
    "    W = np.where(mask_sufficient, R, 0.0)\n",
    "\n",
    "    # Keep only nonnegative similarities if desired\n",
    "    if positive_only:\n",
    "        W = np.maximum(W, 0.0)\n",
    "\n",
    "    # Optional shrink by overlap size (softly downweight low-overlap edges)\n",
    "    if shrink_c is not None and shrink_c > 0:\n",
    "        shrink = O / (O + float(shrink_c))\n",
    "        W = W * shrink\n",
    "\n",
    "    # Zero diagonal\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "\n",
    "    # 3) Build kNN (top-k by weight, skipping zeros)\n",
    "    neighbors = []\n",
    "    weights = []\n",
    "\n",
    "    for i in range(N):\n",
    "        row = W[i].copy()\n",
    "        idx_sorted = np.argsort(row)[::-1]  # sort by weight descending\n",
    "        idx_sorted = idx_sorted[row[idx_sorted] > 0]  # filter out zeros\n",
    "        topk = idx_sorted[:k]\n",
    "        neighbors.append(topk.tolist())\n",
    "        weights.append(row[topk].tolist())\n",
    "\n",
    "    # 4) Symmetrize (mutual kNN) and build edge list\n",
    "    edges = {}\n",
    "\n",
    "    if mutual:\n",
    "        neighbor_sets = [set(ns) for ns in neighbors]\n",
    "        for i in range(N):\n",
    "            for j in neighbors[i]:\n",
    "                if i in neighbor_sets[j]:\n",
    "                    a, b = (i, j) if i < j else (j, i)\n",
    "                    wij = W[i, j]\n",
    "                    wji = W[j, i]\n",
    "                    w = max(wij, wji) # here i could change and put mean also\n",
    "                    if w > 0:\n",
    "                        edges[(a, b)] = max(edges.get((a, b), 0.0), w)\n",
    "    else:\n",
    "        for i in range(N):\n",
    "            for j, w in zip(neighbors[i], weights[i]):\n",
    "                a, b = (i, j) if i < j else (j, i)\n",
    "                edges[(a, b)] = max(edges.get((a, b), 0.0), w)\n",
    "\n",
    "    e_list = list(edges.keys())\n",
    "    w_list = [edges[e] for e in e_list]\n",
    "\n",
    "    g = ig.Graph(n=N, edges=e_list, directed=False)\n",
    "    g.es[\"weight\"] = w_list\n",
    "\n",
    "    return g, w_list, neighbors\n",
    "\n",
    "\n",
    "def alternate_clustering(\n",
    "    df: pd.DataFrame,\n",
    "    apply_filter: bool = True,\n",
    "    min_bin_non_nan_frac: float = 0.2,\n",
    "    min_read_non_nan_frac: float = 0.5,\n",
    "    transform: str | None = None,  # None | 'arcsine' | 'logit'\n",
    "    min_overlap: int = 30,\n",
    "    k: int = 15,\n",
    "    positive_only: bool = True,\n",
    "    shrink_c: float = 30.0,\n",
    "    mutual: bool = True,\n",
    "    leiden_resolution: float = 1.0,\n",
    "    seed: int = 42\n",
    "):\n",
    "    \"\"\"\n",
    "    Pipeline: Masked Pearson correlation (no imputation)\n",
    "    -> weighted mutual kNN graph -> Leiden clustering.\n",
    "\n",
    "    Args:\n",
    "        df: rows = reads, columns = bins, values in [0,1] with NaNs allowed.\n",
    "\n",
    "    Returns:\n",
    "        clusters (np.ndarray of shape (N,)),\n",
    "        graph (igraph.Graph),\n",
    "        df_used (pd.DataFrame after optional filtering/transform)\n",
    "    \"\"\"\n",
    "    if apply_filter:\n",
    "        df_used = filter_by_missingness(\n",
    "            df,\n",
    "            min_bin_non_nan_frac=min_bin_non_nan_frac,\n",
    "            min_read_non_nan_frac=min_read_non_nan_frac\n",
    "        )\n",
    "    else:\n",
    "        df_used = df.copy()\n",
    "\n",
    "    if df_used.shape[0] < 2 or df_used.shape[1] < 2:\n",
    "        raise ValueError(\"Not enough reads or bins after filtering.\")\n",
    "\n",
    "    # Optional transform for proportions\n",
    "    if transform is not None:\n",
    "        if transform == 'arcsine':\n",
    "            arr = np.arcsin(np.sqrt(np.clip(df_used.to_numpy(float), 0.0, 1.0)))\n",
    "            df_used = pd.DataFrame(arr, index=df_used.index, columns=df_used.columns)\n",
    "        elif transform == 'logit':\n",
    "            Xc = np.clip(df_used.to_numpy(float), 1e-3, 1 - 1e-3)\n",
    "            arr = np.log(Xc / (1 - Xc))\n",
    "            df_used = pd.DataFrame(arr, index=df_used.index, columns=df_used.columns)\n",
    "        else:\n",
    "            raise ValueError(\"transform must be None, 'arcsine', or 'logit'\")\n",
    "\n",
    "    # Build graph from masked correlation\n",
    "    g, w_list, _ = build_masked_corr_knn_graph(\n",
    "        df_used,\n",
    "        k=k,\n",
    "        min_overlap=min_overlap,\n",
    "        positive_only=positive_only,\n",
    "        shrink_c=shrink_c,\n",
    "        mutual=mutual\n",
    "    )\n",
    "\n",
    "    # Leiden clustering\n",
    "    part = la.find_partition(\n",
    "        g,\n",
    "        la.RBConfigurationVertexPartition,\n",
    "        weights=g.es[\"weight\"],\n",
    "        resolution_parameter=float(leiden_resolution),\n",
    "        seed=int(seed)\n",
    "    )\n",
    "\n",
    "    clusters = np.array(part.membership, dtype=int)\n",
    "    return clusters, g, df_used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighting_mapping.py\n",
    "\n",
    "# ------------------------------\n",
    "# Column coercion / sorting util\n",
    "# ------------------------------\n",
    "def _coerce_sort(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Strip and coerce column labels to int, collapse duplicates by mean, and sort ascending.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    cols = pd.Series(out.columns, dtype=str).str.strip()\n",
    "    nums = pd.to_numeric(cols, errors='coerce')\n",
    "    if nums.isna().any():\n",
    "        bad = cols[nums.isna()].tolist()\n",
    "        raise ValueError(f\"Non-numeric bin columns found: {bad}\")\n",
    "    out.columns = nums.astype(int)\n",
    "    if out.columns.duplicated().any():\n",
    "        out = out.groupby(level=0, axis=1).mean()\n",
    "    return out.sort_index(axis=1)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Build positional weights\n",
    "# ------------------------------\n",
    "# def build_positional_weights(\n",
    "#     columns,                      # iterable of bin positions (e.g., DataFrame.columns)\n",
    "#     window_bp: int = 500,         # half-window around center to emphasize (e.g., +/- 500 bp)\n",
    "#     center: int = 0,              # Pol2 position (0 if already centered)\n",
    "#     mode: str = \"gaussian\",       # 'gaussian' or 'box'\n",
    "#     inside_weight: float = 1.0,   # weight inside window (for 'box')\n",
    "#     outside_weight: float = 0.2,  # weight outside window (for 'box')\n",
    "#     sigma_bp: float | None = None,# Gaussian sigma in bp (defaults to window_bp/2)\n",
    "#     normalize: bool = True        # normalize to mean ~ 1.0\n",
    "# ) -> pd.Series:\n",
    "#     \"\"\"\n",
    "#     Create a positional weight vector indexed by columns (positions), emphasizing +/- window_bp around center.\n",
    "#     Returns a pd.Series aligned to the provided columns.\n",
    "#     \"\"\"\n",
    "#     pos = pd.to_numeric(pd.Series(list(columns), dtype=str).str.strip(), errors=\"coerce\").astype(int)\n",
    "#     if mode == \"gaussian\":\n",
    "#         # Gaussian weighting: exp(- (pos - center)^2 / (2 * sigma^2))\n",
    "#         sigma = (window_bp / 2.0) if sigma_bp is None else float(sigma_bp)\n",
    "#         w = np.exp(-((pos - center) ** 2) / (2.0 * sigma ** 2))\n",
    "#         w = outside_weight + (inside_weight - outside_weight) * w\n",
    "#     elif mode == \"box\":\n",
    "#         w = np.where(np.abs(pos - center) <= window_bp, inside_weight, outside_weight)\n",
    "#     else:\n",
    "#         raise ValueError(\"mode must be 'gaussian' or 'box'\")\n",
    "\n",
    "#     if normalize:\n",
    "#         mean_val = np.mean(w) if np.mean(w) > 0 else 1.0\n",
    "#         w = w / mean_val\n",
    "#     return pd.Series(w, index=pos)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Masked cosine similarity with NaN handling (intersection)\n",
    "# ---------------------------------------------------------\n",
    "def masked_cosine_cross(\n",
    "    G_df: pd.DataFrame,\n",
    "    P_df: pd.DataFrame,\n",
    "    min_overlap: int = 10,\n",
    "    center_rows: bool = True,\n",
    "    weights=None  # pd.Series indexed by columns (positions), or array-like\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute m×p cosine similarities between rows of G and P, masking NaNs per pair,\n",
    "    aligning columns by intersection, requiring at least min_overlap shared bins,\n",
    "    and applying positional weights if provided (columns scaled by sqrt(weights)).\n",
    "    \"\"\"\n",
    "    Gc = _coerce_sort(G_df)\n",
    "    Pc = _coerce_sort(P_df)\n",
    "\n",
    "    common = np.intersect1d(Gc.columns.values, Pc.columns.values)\n",
    "    if common.size == 0:\n",
    "        raise ValueError(\"No overlapping bins between G and P.\")\n",
    "    Gc = Gc.reindex(columns=common)\n",
    "    Pc = Pc.reindex(columns=common)\n",
    "\n",
    "    # Apply sqrt(weights) as column scaling\n",
    "    # inside masked_cosine_cross, replace the weights handling with:\n",
    "    if weights is not None:\n",
    "        if isinstance(weights, pd.Series):\n",
    "            sw_ser = weights.reindex(common).astype(float)\n",
    "            sw_ser = sw_ser.fillna(1.0)              # ensure constant weights where missing\n",
    "            sw = np.sqrt(np.maximum(sw_ser.to_numpy(), 0.0))\n",
    "        else:\n",
    "            w = np.asarray(weights, float)\n",
    "            if w.shape[0] != common.size:\n",
    "                w_series = pd.Series(w, index=P_df.columns)\n",
    "                sw_ser = w_series.reindex(common).fillna(1.0)\n",
    "                sw = np.sqrt(np.maximum(sw_ser.to_numpy(), 0.0))\n",
    "            else:\n",
    "                sw = np.sqrt(np.maximum(w, 0.0))\n",
    "        Gc = Gc.mul(sw, axis=1)\n",
    "        Pc = Pc.mul(sw, axis=1)\n",
    "\n",
    "    # if weights is not None:\n",
    "    #     if isinstance(weights, pd.Series):\n",
    "    #         sw = np.sqrt(np.maximum(weights.reindex(common).to_numpy(float), 0.0))\n",
    "    #     else:\n",
    "    #         w = np.asarray(weights, float)\n",
    "    #         if w.shape[0] != common.size:\n",
    "    #             w_series = pd.Series(w, index=P_df.columns)\n",
    "    #             sw = np.sqrt(np.maximum(w_series.reindex(common).to_numpy(float), 0.0))\n",
    "    #         else:\n",
    "    #             sw = np.sqrt(np.maximum(w, 0.0))\n",
    "    #     Gc = Gc.mul(sw, axis=1)\n",
    "    #     Pc = Pc.mul(sw, axis=1)\n",
    "\n",
    "    G = Gc.to_numpy(float)\n",
    "    P = Pc.to_numpy(float)\n",
    "    m, d = G.shape\n",
    "    p = P.shape[0]\n",
    "    S = np.zeros((m, p), float)\n",
    "\n",
    "    G_mask = np.isfinite(G)\n",
    "    P_mask = np.isfinite(P)\n",
    "\n",
    "    for i in range(m):\n",
    "        gi, mi = G[i], G_mask[i]\n",
    "        for j in range(p):\n",
    "            pj, mj = P[j], P_mask[j]\n",
    "            ov = mi & mj\n",
    "            n = int(ov.sum())\n",
    "            if n < int(min_overlap):\n",
    "                S[i, j] = 0.0\n",
    "                continue\n",
    "            vi, vj = gi[ov], pj[ov]\n",
    "            if center_rows:\n",
    "                vi -= vi.mean()\n",
    "                vj -= vj.mean()\n",
    "            denom = np.linalg.norm(vi) * np.linalg.norm(vj)\n",
    "            S[i, j] = float(np.dot(vi, vj) / denom) if denom > 0 else 0.0\n",
    "\n",
    "    return S\n",
    "\n",
    "\n",
    "# ------------------------------------------\n",
    "# 2. Pearson similarity (weighted and naive)\n",
    "# ------------------------------------------\n",
    "def _zscore_rows(M: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "    M = np.asarray(M, float)\n",
    "    mu = np.nanmean(M, axis=1, keepdims=True)\n",
    "    sd = np.nanstd(M, axis=1, keepdims=True)\n",
    "    sd = np.where(sd < eps, eps, sd)\n",
    "    return (M - mu) / sd\n",
    "\n",
    "def _pairwise_pearson(G: np.ndarray, P: np.ndarray, min_overlap: int = 2) -> np.ndarray:\n",
    "    G = np.asarray(G, float)\n",
    "    P = np.asarray(P, float)\n",
    "    m, d = G.shape\n",
    "    p = P.shape[0]\n",
    "    S = np.zeros((m, p), float)\n",
    "    for i in range(m):\n",
    "        gi = G[i]\n",
    "        for j in range(p):\n",
    "            pj = P[j]\n",
    "            mask = np.isfinite(gi) & np.isfinite(pj)\n",
    "            if mask.sum() < int(min_overlap):\n",
    "                S[i, j] = 0.0\n",
    "                continue\n",
    "            gi_m, pj_m = gi[mask], pj[mask]\n",
    "            gi_sd, pj_sd = gi_m.std(), pj_m.std()\n",
    "            gi_m = (gi_m - gi_m.mean()) / (gi_sd if gi_sd > 0 else 1.0)\n",
    "            pj_m = (pj_m - pj_m.mean()) / (pj_sd if pj_sd > 0 else 1.0)\n",
    "            S[i, j] = float(np.dot(gi_m, pj_m) / mask.sum())\n",
    "    return S\n",
    "\n",
    "def _pairwise_weighted_pearson_df(\n",
    "    G_df: pd.DataFrame, P_df: pd.DataFrame, weights: pd.Series, min_overlap: int = 2\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Weighted Pearson correlation between rows of G_df and P_df using per-bin weights (Series).\n",
    "    Columns are aligned to intersection; weights reindexed to the intersection.\n",
    "    \"\"\"\n",
    "    Gc = _coerce_sort(G_df)\n",
    "    Pc = _coerce_sort(P_df)\n",
    "    common = np.intersect1d(Gc.columns.values, Pc.columns.values)\n",
    "    if common.size == 0:\n",
    "        raise ValueError(\"No overlapping bins between G and P.\")\n",
    "    Gc = Gc.reindex(columns=common)\n",
    "    Pc = Pc.reindex(columns=common)\n",
    "    if weights is None:\n",
    "        w= np.ones(common.size, float)\n",
    "    else:\n",
    "        w = weights.reindex(common).to_numpy(float)\n",
    "        w = np.where(w < 0, 0.0, w)\n",
    "\n",
    "    G = Gc.to_numpy(float)\n",
    "    P = Pc.to_numpy(float)\n",
    "    m, d = G.shape\n",
    "    p = P.shape[0]\n",
    "    S = np.zeros((m, p), float)\n",
    "\n",
    "    G_mask = np.isfinite(G)\n",
    "    P_mask = np.isfinite(P)\n",
    "\n",
    "    for i in range(m):\n",
    "        gi, mi = G[i], G_mask[i]\n",
    "        for j in range(p):\n",
    "            pj, mj = P[j], P_mask[j]\n",
    "            mask = (mi & mj)\n",
    "            if mask.sum() < int(min_overlap):\n",
    "                S[i, j] = 0.0\n",
    "                continue\n",
    "            wi = w[mask]\n",
    "            xi = gi[mask]\n",
    "            yj = pj[mask]\n",
    "            W = wi.sum()\n",
    "            if W <= 0:\n",
    "                S[i, j] = 0.0\n",
    "                continue\n",
    "            mu_x = (wi * xi).sum() / W\n",
    "            mu_y = (wi * yj).sum() / W\n",
    "            var_x = (wi * (xi - mu_x) ** 2).sum() / W\n",
    "            var_y = (wi * (yj - mu_y) ** 2).sum() / W\n",
    "            denom = np.sqrt(var_x * var_y)\n",
    "            if denom <= 0:\n",
    "                S[i, j] = 0.0\n",
    "                continue\n",
    "            cov_xy = (wi * (xi - mu_x) * (yj - mu_y)).sum() / W\n",
    "            S[i, j] = float(cov_xy / denom)\n",
    "\n",
    "    return S\n",
    "\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3. Unified similarity API (cosine/pearson)\n",
    "# ------------------------------------------\n",
    "def compute_similarity_matrix(\n",
    "    G,\n",
    "    P,\n",
    "    method: str = 'pearson',\n",
    "    use_abs: bool = False,\n",
    "    center_rows: bool = True,\n",
    "    weights=None,            # pd.Series (positional) or array-like; for cosine and weighted pearson\n",
    "    min_overlap: int = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute similarity S and distance D between rows of G and rows of P.\n",
    "\n",
    "    method:\n",
    "      - 'pearson': G/P arrays or DataFrames; if weights is a Series and G/P are DataFrames,\n",
    "                   uses weighted Pearson; otherwise unweighted Pearson.\n",
    "      - 'cosine' : G/P must be DataFrames; columns aligned to intersection; masked cosine used.\n",
    "    \"\"\"\n",
    "    if method == 'pearson':\n",
    "        if isinstance(G, pd.DataFrame) and isinstance(P, pd.DataFrame) and isinstance(weights, pd.Series):\n",
    "            S = _pairwise_weighted_pearson_df(G_df=G, P_df=P, weights=weights, min_overlap=min_overlap)\n",
    "            S = np.nan_to_num(S, nan=0.0)\n",
    "        else:\n",
    "            G_arr = np.asarray(G, float) if not isinstance(G, pd.DataFrame) else _coerce_sort(G).to_numpy(float)\n",
    "            P_arr = np.asarray(P, float) if not isinstance(P, pd.DataFrame) else _coerce_sort(P).to_numpy(float)\n",
    "            # Align by intersection if DataFrames were passed\n",
    "            if isinstance(G, pd.DataFrame) and isinstance(P, pd.DataFrame):\n",
    "                common = np.intersect1d(_coerce_sort(G).columns.values, _coerce_sort(P).columns.values)\n",
    "                G_arr = _coerce_sort(G).reindex(columns=common).to_numpy(float)\n",
    "                P_arr = _coerce_sort(P).reindex(columns=common).to_numpy(float)\n",
    "            Zg = _zscore_rows(G_arr)\n",
    "            Zp = _zscore_rows(P_arr)\n",
    "            S = _pairwise_pearson(Zg, Zp, min_overlap=min_overlap)\n",
    "            S = np.nan_to_num(S, nan=0.0)\n",
    "        if use_abs:\n",
    "            S = np.abs(S)\n",
    "        D = 1.0 - S\n",
    "        D[D < 0] = 0.0\n",
    "        prot_ids = list(P.index) if isinstance(P, pd.DataFrame) else list(range(np.asarray(P).shape[0]))\n",
    "        return S, D, prot_ids\n",
    "\n",
    "    elif method == 'cosine':\n",
    "        if not isinstance(G, pd.DataFrame) or not isinstance(P, pd.DataFrame):\n",
    "            raise ValueError(\"For masked cosine, pass G and P as DataFrames (columns = positions).\")\n",
    "        S = masked_cosine_cross(G_df=G, P_df=P, min_overlap=min_overlap, center_rows=center_rows, weights=weights)\n",
    "        if use_abs:\n",
    "            S = np.abs(S)\n",
    "        D = 1.0 - S\n",
    "        D[D < 0] = 0.0\n",
    "        prot_ids = list(P.index)\n",
    "        return S, D, prot_ids\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'pearson' or 'cosine'.\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. Hungarian assignment (one-to-one per gene)\n",
    "# -----------------------------------------------------\n",
    "def assign_gene_clusters_to_consensus(\n",
    "    G,\n",
    "    meta: pd.DataFrame,\n",
    "    P,\n",
    "    method: str = 'pearson',\n",
    "    use_abs: bool = False,\n",
    "    center_rows: bool = True,\n",
    "    weights=None,\n",
    "    min_overlap: int = 10,\n",
    "    min_similarity: float | None = None,\n",
    "    allow_unassigned: bool = True,\n",
    "    capacity_per_type: int = 1\n",
    "):\n",
    "    \"\"\"\n",
    "    Map gene clusters (rows of G) to bulk prototypes (rows of P).\n",
    "    meta must have ['gene_id' or 'gene_tss', 'cluster_id', 'size'] aligned to rows of G.\n",
    "    \"\"\"\n",
    "    S, D_base, prot_ids = compute_similarity_matrix(\n",
    "        G=G, P=P, method=method, use_abs=use_abs,\n",
    "        center_rows=center_rows, weights=weights, min_overlap=min_overlap\n",
    "    )\n",
    "\n",
    "    meta_df = meta.copy()\n",
    "    if 'size' not in meta_df.columns:\n",
    "        meta_df['size'] = np.nan\n",
    "    gene_col = 'gene_id' if 'gene_id' in meta_df.columns else ('gene_tss' if 'gene_tss' in meta_df.columns else None)\n",
    "    if gene_col is None:\n",
    "        raise ValueError(\"meta must contain 'gene_id' or 'gene_tss'.\")\n",
    "\n",
    "    assignments = []\n",
    "    for gene_id, row_idx in meta_df.groupby(gene_col).groups.items():\n",
    "        row_idx = list(row_idx)\n",
    "        D = D_base[row_idx, :]\n",
    "\n",
    "        if capacity_per_type > 1:\n",
    "            P_rep = np.repeat(np.arange(D.shape[1]), repeats=int(capacity_per_type))\n",
    "            D_aug = np.tile(D, reps=(1, int(capacity_per_type)))\n",
    "        else:\n",
    "            P_rep = np.arange(D.shape[1])\n",
    "            D_aug = D\n",
    "\n",
    "        if allow_unassigned:\n",
    "            penalty = (1.0 - float(min_similarity)) if min_similarity is not None else float(np.nanmax(D_aug) + 0.05)\n",
    "            dummy = np.full((D_aug.shape[0], D_aug.shape[0]), penalty, dtype=float)\n",
    "            D_final = np.hstack([D_aug, dummy])\n",
    "            col_map = np.concatenate([P_rep, -np.ones(dummy.shape[1], dtype=int)])\n",
    "        else:\n",
    "            D_final = D_aug\n",
    "            col_map = P_rep\n",
    "\n",
    "        r_idx, c_idx = linear_sum_assignment(D_final)\n",
    "\n",
    "        for r, c in zip(r_idx, c_idx):\n",
    "            cons_col = col_map[c]\n",
    "            best_cost = D_final[r, c]\n",
    "            sim = float(1.0 - best_cost)\n",
    "            row_costs = D_final[r]\n",
    "            mask = np.ones_like(row_costs, dtype=bool); mask[c] = False\n",
    "            second_best_cost = np.min(row_costs[mask]) if mask.any() else np.nan\n",
    "            second_best_sim = float(1.0 - second_best_cost) if np.isfinite(second_best_cost) else np.nan\n",
    "            margin = float(second_best_cost - best_cost) if np.isfinite(second_best_cost) else np.nan\n",
    "            cons_id = None if cons_col < 0 else prot_ids[int(cons_col)]\n",
    "            assignments.append({\n",
    "                gene_col: gene_id,\n",
    "                'cluster_id': meta_df.iloc[r]['cluster_id'],\n",
    "                'size': meta_df.iloc[r]['size'],\n",
    "                'consensus_id': cons_id,\n",
    "                'similarity': sim,\n",
    "                'second_best_similarity': second_best_sim,\n",
    "                'margin': margin\n",
    "            })\n",
    "\n",
    "    assign_df = pd.DataFrame(assignments)\n",
    "    return assign_df, S, D_base\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gene_mapping_heatmap(\n",
    "    assign_df: pd.DataFrame,\n",
    "    S: np.ndarray,                  # full similarity matrix returned by assign_gene_clusters_to_consensus\n",
    "    meta: pd.DataFrame,             # meta passed to assign (aligned to rows of G)\n",
    "    P,                              # bulk prototypes (DataFrame for cosine, array for pearson)\n",
    "    gene_id: str,\n",
    "    sort_rows: bool = True,         # sort by assigned prototype then by max similarity\n",
    "    cmap: str = \"viridis\",\n",
    "    vmin: float = 0.0,\n",
    "    vmax: float = 1.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a heatmap of similarities (rows = gene clusters, cols = bulk prototypes)\n",
    "    for a single gene and overlay markers for the Hungarian assignment.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - S must be the full similarity matrix returned by `assign_gene_clusters_to_consensus`.\n",
    "      Rows of S must align with rows of `meta` (i.e., meta.loc[i] corresponds to S[i]).\n",
    "    - P can be a DataFrame (then prot IDs are P.index) or a numpy array (then prot IDs are 0..P.shape[0]-1).\n",
    "    \"\"\"\n",
    "    # Prototype IDs (columns of S)\n",
    "    if isinstance(P, pd.DataFrame):\n",
    "        prot_ids = list(P.index)\n",
    "    else:\n",
    "        prot_ids = list(range(P.shape[0]))\n",
    "\n",
    "    # Row indices for the selected gene (rows of S)\n",
    "    idx_rows = meta.index[meta[\"gene_tss\"] == gene_id].tolist()\n",
    "    if not idx_rows:\n",
    "        raise ValueError(f\"No rows in meta for gene_id={gene_id}.\")\n",
    "\n",
    "    # Subset similarity and labels (rows in the same order as S)\n",
    "    S_sub = S[idx_rows, :]\n",
    "    row_labels = meta.loc[idx_rows, \"cluster_id\"].astype(int).tolist()\n",
    "    col_labels = prot_ids\n",
    "\n",
    "    # Row ordering / sorting\n",
    "    if sort_rows:\n",
    "        ass_sub = assign_df[assign_df[\"gene_tss\"] == gene_id].copy()\n",
    "        # map cluster_id -> assigned consensus_id\n",
    "        ass_map = {int(r[\"cluster_id\"]): r[\"consensus_id\"] for _, r in ass_sub.iterrows()}\n",
    "        sort_keys = []\n",
    "        for i, cid in enumerate(row_labels):\n",
    "            assigned = ass_map.get(int(cid), None)\n",
    "            j_ass = col_labels.index(assigned) if (assigned is not None and assigned in col_labels) else -1\n",
    "            # use -max_similarity so that higher similarity sorts earlier within same assigned group\n",
    "            sort_keys.append((j_ass, -float(np.nanmax(S_sub[i])) if S_sub.size else 0.0))\n",
    "        order = sorted(range(len(sort_keys)), key=lambda ii: sort_keys[ii])\n",
    "        S_plot = S_sub[order, :]\n",
    "        row_labels_plot = [row_labels[i] for i in order]\n",
    "    else:\n",
    "        S_plot = S_sub\n",
    "        row_labels_plot = row_labels\n",
    "\n",
    "    # Create heatmap\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(1.0 + 0.4 * len(col_labels), 0.6 + 0.4 * len(row_labels_plot))\n",
    "    )\n",
    "    sns.heatmap(\n",
    "        S_plot,\n",
    "        xticklabels=col_labels,\n",
    "        yticklabels=row_labels_plot,\n",
    "        cmap=cmap,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        cbar_kws={\"label\": \"similarity\"},\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(f\"Mapping of {gene_id} clusters to bulk prototypes\")\n",
    "    ax.set_xlabel(\"bulk consensus ID\")\n",
    "    ax.set_ylabel(\"gene cluster ID\")\n",
    "\n",
    "    # Overlay assignment markers\n",
    "    ass_sub = assign_df[assign_df[\"gene_tss\"] == gene_id]\n",
    "    # Build CID -> row index in the plotted order\n",
    "    row_index_map = {cid: i for i, cid in enumerate(row_labels_plot)}\n",
    "    for _, r in ass_sub.iterrows():\n",
    "        cid = int(r[\"cluster_id\"])\n",
    "        cons_id = r[\"consensus_id\"]\n",
    "        if cons_id is None or cons_id not in col_labels:\n",
    "            continue\n",
    "        i = row_index_map.get(cid, None)\n",
    "        j = col_labels.index(cons_id)\n",
    "        if i is None:\n",
    "            continue\n",
    "        # place marker at the center of the heatmap cell\n",
    "        ax.scatter(j + 0.5, i + 0.5, s=60, facecolors=\"none\", edgecolors=\"white\", linewidths=1.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_assignment_summary(assign_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Bar chart: number of gene clusters assigned to each bulk prototype (across all genes).\n",
    "    Unassigned clusters (consensus_id == NaN) are dropped.\n",
    "    \"\"\"\n",
    "    df = assign_df.dropna(subset=[\"consensus_id\"])\n",
    "    counts = df.groupby(\"consensus_id\").size().sort_values(ascending=False)\n",
    "    fig, ax = plt.subplots(figsize=(8, 3))\n",
    "    counts.plot(kind=\"bar\", ax=ax, color=\"#4c72b0\")\n",
    "    ax.set_ylabel(\"# gene clusters assigned\")\n",
    "    ax.set_xlabel(\"bulk consensus ID\")\n",
    "    ax.set_title(\"Assignment summary across genes\")\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def recolor_meta_by_bulk(assign_df, meta_df, bulk_color_map, gene_id):\n",
    "    \"\"\"\n",
    "    Return a copy of meta_df for `gene_id` with 'cluster_color' replaced by the assigned\n",
    "    bulk prototype color (falls back to original color if unassigned).\n",
    "    \"\"\"\n",
    "    m = meta_df.copy()\n",
    "    ass_sub = assign_df[assign_df[\"gene_tss\"] == gene_id]\n",
    "    ass_map = {int(r[\"cluster_id\"]): r[\"consensus_id\"] for _, r in ass_sub.iterrows()}\n",
    "\n",
    "    colors = []\n",
    "    for _, r in m.iterrows():\n",
    "        cid = int(r[\"cluster_id\"])\n",
    "        cons = ass_map.get(cid, None)\n",
    "        col = bulk_color_map.get(cons, r.get(\"cluster_color\", None))\n",
    "        colors.append(col)\n",
    "    m = m.assign(cluster_color=colors)\n",
    "    return m\n",
    "\n",
    "\n",
    "def plot_assignment_confidence(assign_df: pd.DataFrame, gene_id: str | None = None):\n",
    "    \"\"\"\n",
    "    Scatter plot of best similarity vs. margin (second_best_similarity - best_similarity).\n",
    "    Small margin => ambiguous assignment.\n",
    "    \"\"\"\n",
    "    df = assign_df.copy()\n",
    "    if gene_id is not None:\n",
    "        df = df[df[\"gene_tss\"] == gene_id]\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.scatter(df[\"similarity\"], df[\"margin\"], s=30, alpha=0.7)\n",
    "    ax.set_xlabel(\"best similarity\")\n",
    "    ax.set_ylabel(\"margin (second-best − best)\")\n",
    "    ax.set_title(\"Assignment confidence\" + (f\" ({gene_id})\" if gene_id else \"\"))\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "scripts_dir = os.path.abspath(\"../scripts\")  # note the ../\n",
    "if scripts_dir not in sys.path:\n",
    "    sys.path.append(scripts_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_needed_for_pipeline import (calculate_pol2_position, \n",
    "    preprocess_dataframe, \n",
    "    filter_reads_per_gene_middle_bin_name, \n",
    "    bin_then_matrix, \n",
    "    process_into_matrix, \n",
    "    handling_NaN, \n",
    "    preprocess_long_for_plot, \n",
    "    plot_reads_long, \n",
    "    get_genes_list, \n",
    "    get_groups_df_list,\n",
    "    clustering_final, \n",
    "    compute_cluster_metrics,\n",
    "    plot_umap, \n",
    "    dict_id_cluster_color, \n",
    "    dict_to_df, \n",
    "    merge, \n",
    "    start_end_center, \n",
    "    summary, \n",
    "    compute_bulk_centroids, \n",
    "    compute_gene_centroids, \n",
    "    plot_centroids_with_shading,\n",
    "    build_positional_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### Opening the text document that contains the columns description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/gc_peak2_all_colnames.txt\", \"r\") as f:\n",
    "    description_colnames = f.read()\n",
    "\n",
    "print(description_colnames)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Hard coding variables useful :\n",
    "- treatment_group list\n",
    "- hex_colors list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##LIST CONTAINITNG THE GROUPS NAMES \n",
    "treatment_groups = [\n",
    "        'BT474_mV_72hNHWD',\n",
    "        'BT474_mV_72hSTC15',\n",
    "        'BT474_mV_high_Untreated',\n",
    "        'BT474_mV_low_Untreated',\n",
    "        'BT474_mV_Untreated_Unsorted']\n",
    "\n",
    "## ARBITRARY CHOSEN COLORS FOR THE CLUSTERS (THEY NEED TO HAVE A HIGH VALUE AND CHROMA TO STAND OUT ON A GREY BACKGROUND)\n",
    "hex_colors = [\n",
    "    \"#0e67a7\", \"#ff7f0e\", \"#a0e468\", \"#d62728\", \"#9467bd\",\n",
    "    \"#672417\", \"#e377c2\", \"#f5f523\", \"#28e0f5\", \"#3214a8\",\n",
    "    \"#ca9d16\", \"#04a887\", \"#8c564b\", \"#17becf\", \"#bcbd22\",\n",
    "    \"#2ca02c\", \"#1f77b4\", \"#ff9896\", \"#c5b0d5\", \"#98df8a\",\n",
    "    \"#ffbb78\", \"#aec7e8\", \"#7f7f7f\", \"#c49c94\", \"#dbdb8d\",\n",
    "    \"#9edae5\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "##### Opening the datafile:\n",
    "Calling the dataframe df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/gc_peak2_all.txt\", delim_whitespace=True)\n",
    "\n",
    "print(f'The shape of the dataframe is of {df.shape}')\n",
    "#print(df.dtypes)\n",
    "#print(df.columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Calling the bulk dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk = pd.read_csv(\"../data/camille_average_profile_pol2_by_cluster.txt\", delim_whitespace=True)\n",
    "\n",
    "print(f'The shape of the dataframe is of {df.shape}')\n",
    "#print(df.dtypes)\n",
    "#print(df.columns)\n",
    "# is_constant = df_bulk.groupby('cluster')['cov'].nunique().eq(1)\n",
    "\n",
    "# print(\"cov constant per cluster:\", is_constant.all())\n",
    "\n",
    "df_bulk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "##### Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### BINNING THE BULK DATA TO BA ABLE TO DO REASSIGNMENT \n",
    "\n",
    "d= bin_then_matrix(\n",
    "    df_bulk,\n",
    "    indexes=['cluster'],\n",
    "    bin_size=50\n",
    ")\n",
    "\n",
    " # ---- Mean methylation per (cluster, bin) ----\n",
    "meth_agg = (\n",
    "        d.groupby(['cluster', 'bin'], as_index=False)\n",
    "        .agg(meth_mean=('meth', 'mean'))\n",
    "    )\n",
    "\n",
    "# Take unique cov per cluster (assumes cov constant per cluster)\n",
    "cov_cluster = d.groupby('cluster')['cov'].first()\n",
    "cov_rows = []\n",
    "for cid, sub in meth_agg.groupby('cluster'):\n",
    "    cov_val = float(cov_cluster.get(cid, np.nan))\n",
    "    for b in sub['bin'].unique():\n",
    "        cov_rows.append({'cluster': cid, 'bin': b, 'cov_bin': cov_val})\n",
    "cov_agg = pd.DataFrame(cov_rows)\n",
    "\n",
    "# ---- Merge meth and coverage ----\n",
    "agg = pd.merge(meth_agg, cov_agg, on=['cluster', 'bin'], how='left')\n",
    "\n",
    "# ---- Pivot to wide profiles ----\n",
    "profiles_df_bulk_binned = agg.pivot(index='cluster', columns='bin', values='meth_mean')\n",
    "coverage_df_bulk_binned = agg.pivot(index='cluster', columns='bin', values='cov_bin')\n",
    "\n",
    "    # ---- Sort columns and set names ----\n",
    "positions_bulk_binned = np.array(sorted(profiles_df_bulk_binned.columns.astype(int)), dtype=int)\n",
    "profiles_df_bulk_binned = profiles_df_bulk_binned.reindex(columns=positions_bulk_binned)\n",
    "coverage_df_bulk_binned = coverage_df_bulk_binned.reindex(columns=positions_bulk_binned)\n",
    "\n",
    "profiles_df_bulk_binned.index.name = 'cluster'\n",
    "profiles_df_bulk_binned.columns = pd.Index(positions_bulk_binned, name='C_pos')\n",
    "coverage_df_bulk_binned.index.name = 'cluster'\n",
    "coverage_df_bulk_binned.columns = pd.Index(positions_bulk_binned, name='C_pos')\n",
    "\n",
    "\n",
    "n_metric = cov_cluster.astype(float)\n",
    "total_cov= float(cov_cluster.sum()) if cov_cluster.sum() is not None else 0.0\n",
    "proportions = (cov_cluster / (total_cov if total_cov > 0 else 1.0)) * 100.0\n",
    "\n",
    "meta_rows = []\n",
    "for cid in profiles_df_bulk_binned.index:\n",
    "        meta_rows.append({\n",
    "            'cluster_id': cid if isinstance(cid, (int, np.integer)) else str(cid),\n",
    "            'cov_total': float(n_metric.get(cid, np.nan)),\n",
    "            'proportion': float(proportions.get(cid, 0.0))\n",
    "        })\n",
    "meta_df_bulk_binned = pd.DataFrame(meta_rows).sort_values('cluster_id').reset_index(drop=True)\n",
    "\n",
    "profiles_df_bulk_binned, \n",
    "meta_df_bulk_binned\n",
    "coverage_df_bulk_binned, \n",
    "positions_bulk_binned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['read_strand'].value_counts())\n",
    "print(df['motif_stand'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "##RUNNING THE CODE ON THE ACTUAL DATASET -- applying preprocess_dataframe\n",
    "columns_to_drop=['read_strand', 'N', 'n_meth_motif',\n",
    "       'perc_meth_in_motif','peak_cov', 'peak_meth', 'C_in_motif',\n",
    "       'n', 'read_meth_mean', 'motif_id', 'gene2', 'bound', 'cov', 'peakid', 'meth_C_in_motif','read_meth_C_in_motif']\n",
    "\n",
    "df_proc = preprocess_dataframe(df, columns_to_drop)\n",
    "\n",
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHOLE PREPROCESSED DF THAT GETS BINNED UNDER METHYLATION MATRIX (i need it to flter the genes that we want to work on)\n",
    "\n",
    "df_whole_matrix= process_into_matrix(\n",
    "    df_proc,\n",
    "    gene=None, #the id taken from the column gene_tss, only if we want to process per gene\n",
    "    bin_size= 50)\n",
    "\n",
    "df_whole_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WHOLE PREPROCESSED DF THAT IS UNBINNED UNDER METHYLATION MATRIX (i need it plot the average methylation profile unbinned)\n",
    "\n",
    "# df_whole_matrix_unbinned= process_into_matrix(df_proc,gene=None,bin_size= 1)\n",
    "# df_whole_matrix_unbinned.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTERING AND KEEPING ONLY THE GENES THAT ARE SUITABLE (HAVE ENOUGH READS OVERLAPPING AND LONG ENOUGH)\n",
    "\n",
    "df_filtered, filtered_regions = filter_reads_per_gene_middle_bin_name(\n",
    "    df_whole_matrix, \n",
    "    middle_bin_name=None, \n",
    "    min_reads =50, \n",
    "    min_bins =20,\n",
    "    require_middle_bin=True)\n",
    "\n",
    "print(f'THe shape of the filtered dataframe is of {df_filtered.shape}')\n",
    "print(f'There is {df_filtered.index.get_level_values(\"gene_tss\").nunique()} different genes in this dataframe')\n",
    "\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GETTING THE FILTERED GENES NAMES AND SUB DF\n",
    "gene_names, gene_df = get_genes_list(df_filtered)\n",
    "print(gene_names)\n",
    "\n",
    "\n",
    "# gene_names_unbinned, gene_df_unbinned = get_genes_list(df_whole_matrix_unbinned)\n",
    "# print(gene_names_unbinned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_to_keep = df_filtered.index.get_level_values('gene_tss').unique()\n",
    "\n",
    "# df_whole_matrix_unbinned = df_whole_matrix_unbinned[df_whole_matrix_unbinned.index.get_level_values('gene_tss').isin(genes_to_keep)]\n",
    "\n",
    "# df_whole_matrix_unbinned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECTNG A GENE OF THE LIST OF GENES (for i=19, SETD1A_30958295_30958295)\n",
    "gene= gene_names[14]\n",
    "df_gene= gene_df[14]\n",
    "print(gene)\n",
    "\n",
    "\n",
    "# df_gene_unbinned = gene_df_unbinned[80]\n",
    "# print(df_gene_unbinned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLotting for a gene - no color, whole gene, all reads\n",
    "\n",
    "# df_to_plot= preprocess_long_for_plot(df_proc)\n",
    "# plot_reads_long(df_to_plot,filters={'gene_tss':gene}, facet_by=None, color_by=None, hex_colors=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting for a gene per group - no. color, all reads, faceting by group\n",
    "# plot_reads_long(df_to_plot,filters={'gene_tss':gene}, facet_by= 'group', color_by=None, hex_colors=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "##### Running the clustering on the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLUSTERING WITH PCA + EUCLIDEAN + LAPLACIAN KERNEL\n",
    "\n",
    "df_PCA_euclidean, X_PCA_euclidean, partition_PCA_euclidean, clusters_PCA_euclidean, metrics_PCA_euclidean = clustering_final(\n",
    "        df_gene,\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,\n",
    "        pca_or_not=True,\n",
    "        n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "        metric='euclidean',          # 'euclidean' or 'cosine'\n",
    "        transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=0.8,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "# print(clusters_PCA_euclidean)\n",
    "\n",
    "# # PLOTTING UMAP FOR PCA + EUCLIDEAN + LAPLACIAN KERNEL\n",
    "embedding_PCA_euclidean, fig_PCA_euclidean = plot_umap(\n",
    "        X_PCA_euclidean,\n",
    "        clusters_PCA_euclidean,\n",
    "        n_neighbors=25,\n",
    "        min_dist=0.1,\n",
    "        metric='euclidean',      # for Pipeline 2, use 'euclidean'\n",
    "        transform=None,          # None | 'logit' | 'arcsine' (use only if X are raw proportions)\n",
    "        n_pcs=None,              # set if X are raw features; None if X are already PCs\n",
    "        standardize=False,       # True if using raw features without PCA\n",
    "        seed=42,\n",
    "        palette=hex_colors,            # optional list/array or matplotlib colormap name\n",
    "        title=\"PCA + euclidean + laplacian\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# CREATING A NEW DATAFRAME WITH THE CLUSTER ASSIGNMENTS AND COLORS\n",
    "read_dict_PCA_euclidean = dict_id_cluster_color(df_PCA_euclidean, clusters_PCA_euclidean, hex_colors)\n",
    "df_dict_PCA_euclidean = dict_to_df(read_dict_PCA_euclidean)\n",
    "df_test_PCA_euclidean= merge(df_proc, df_dict_PCA_euclidean)\n",
    "\n",
    "#PREPROCESSING THE DF FOR LONG READS PLOTTING \n",
    "df_test_plot_PCA_euclidean = preprocess_long_for_plot(df_test_PCA_euclidean,\n",
    "                                                          include_locus_cluster=True,\n",
    "                                                          filter_outliers= True,\n",
    "                                                          max_span_bp=None,     #i'm letting the filtering be based on the span_quantile\n",
    "                                                          span_quantile=0.99,\n",
    "                                                          require_center_inside=True,\n",
    "                                                          min_cpg=1,\n",
    "                                                          cpg_window_bp=5000\n",
    "                                                          )\n",
    "\n",
    "# PLOTTING THE LONG READS FOR PCA + EUCLIDEAN + LAPLACIAN KERNEL\n",
    "plot_reads_long(\n",
    "        df_test_plot_PCA_euclidean,\n",
    "        filters={\n",
    "            # \"gene_tss\": gene, \n",
    "            'group':['BT474_mV_high_Untreated',\n",
    "            'BT474_mV_low_Untreated',\n",
    "            'BT474_mV_Untreated_Unsorted']},\n",
    "        # facet_by='group',\n",
    "        color_by=\"locus_cluster\",\n",
    "        gene=gene,\n",
    "        hex_colors=hex_colors,\n",
    "        figsize=(12,6)\n",
    "    )\n",
    "\n",
    "#ISOLATING ONLY THE INTERESTING GROUPS FOR SUMMARY STATS\n",
    "# df_only_interesting_groups_PCA_euclidean = df_PCA_euclidean[df_PCA_euclidean.index.get_level_values('group').isin([\n",
    "#         'BT474_mV_high_Untreated',\n",
    "#         'BT474_mV_low_Untreated',\n",
    "#         'BT474_mV_Untreated_Unsorted'\n",
    "#     ])]\n",
    "\n",
    "# df_only_interesting_groups_PCA_euclidean = merge(df_only_interesting_groups_PCA_euclidean, df_dict_PCA_euclidean)\n",
    "# clusters_of_interest_PCA_euclidean = df_only_interesting_groups_PCA_euclidean['locus_cluster'].tolist() \n",
    "# summary(df_only_interesting_groups_PCA_euclidean, clusters_of_interest_PCA_euclidean, gene=gene)\n",
    "\n",
    "\n",
    "# COMPUTING THE GENE CENTROIDS TO PLOT AVERAGE PROFILES PER CLUSTER\n",
    "profiles_df_PCA_euclidean, coverage_df_PCA_euclidean, meta_df_PCA_euclidean, positions_PCA_euclidean= compute_gene_centroids(\n",
    "                                                                    df_PCA_euclidean,\n",
    "                                                                    df_dict_PCA_euclidean,\n",
    "                                                                    gene_tss=gene,\n",
    "                                                                   )\n",
    "\n",
    "# PLOTTING THE AVERAGE PROFILES PER CLUSTER FOR PCA + EUCLIDEAN + LAPLACIAN KERNEL\n",
    "plot_centroids_with_shading(\n",
    "    profiles_df_PCA_euclidean,\n",
    "    positions_PCA_euclidean,\n",
    "    meta_df_PCA_euclidean,\n",
    "    coverage_df_PCA_euclidean,\n",
    "    hex_colors,\n",
    "    proportional_height=True,\n",
    "    smooth_sigma = 0,\n",
    "    title=gene + 'Average DNA Methylation Profiles per Cluster',\n",
    "    missingness_threshold=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build weights emphasizing ±500 bp around Pol2 (positions assumed to be df.columns)\n",
    "weights_pos = build_positional_weights(\n",
    "    columns=df_gene.columns,\n",
    "    window_bp=300,\n",
    "    center=0,\n",
    "    mode='gaussian',\n",
    "    inside_weight=1.0,\n",
    "    outside_weight=0.2,\n",
    "    sigma_bp=None,           # default window_bp/2\n",
    "    normalize_mean=True      # average weight ~ 1.0\n",
    ")\n",
    "\n",
    "df_used, X_emb, part, labels, metrics = clustering_final(\n",
    "    df=df_gene,\n",
    "    n_neighbors=15,\n",
    "    nan_threshold=0.7,\n",
    "    nan_method='drop',\n",
    "    scaling=False,\n",
    "    pca_or_not=True,            # weighting applied pre-PCA by default\n",
    "    n_pcs=None,\n",
    "    metric='euclidean',         # or 'cosine'\n",
    "    transform='arcsine',\n",
    "    kernel_type='laplacian',\n",
    "    leiden_resolution=0.8,\n",
    "    seed=42,\n",
    "    pos_weights=weights_pos,    # <-- emphasize central bins\n",
    "    weight_stage='pre_pca'\n",
    ")\n",
    "print(part) \n",
    "\n",
    "clusters = np.asarray(part.membership, dtype=int)\n",
    "\n",
    "print (clusters)\n",
    "# # PLOTTING UMAP FOR PCA + EUCLIDEAN + LAPLACIAN KERNEL\n",
    "embedding_PCA_euclidean, fig_PCA_euclidean = plot_umap(\n",
    "        X_emb,\n",
    "        clusters,\n",
    "        n_neighbors=25,\n",
    "        min_dist=0.1,\n",
    "        metric='euclidean',      # for Pipeline 2, use 'euclidean'\n",
    "        transform=None,          # None | 'logit' | 'arcsine' (use only if X are raw proportions)\n",
    "        n_pcs=None,              # set if X are raw features; None if X are already PCs\n",
    "        standardize=False,       # True if using raw features without PCA\n",
    "        seed=42,\n",
    "        palette=hex_colors,            # optional list/array or matplotlib colormap name\n",
    "        title=\"PCA + euclidean + laplacian + weighted bins\",\n",
    "        gene = 'Gene'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# CREATING A NEW DATAFRAME WITH THE CLUSTER ASSIGNMENTS AND COLORS\n",
    "read_dict = dict_id_cluster_color(df_used, clusters, hex_colors)\n",
    "df_dict = dict_to_df(read_dict)\n",
    "df_test= merge(df_proc, df_dict)\n",
    "\n",
    "#PREPROCESSING THE DF FOR LONG READS PLOTTING \n",
    "df_test_plot = preprocess_long_for_plot(df_test,\n",
    "                                                          include_locus_cluster=True,\n",
    "                                                          filter_outliers= True,\n",
    "                                                          max_span_bp=None,     #i'm letting the filtering be based on the span_quantile\n",
    "                                                          span_quantile=0.99,\n",
    "                                                          require_center_inside=True,\n",
    "                                                          min_cpg=1,\n",
    "                                                          cpg_window_bp=5000\n",
    "                                                          )\n",
    "\n",
    "# PLOTTING THE LONG READS FOR PCA + EUCLIDEAN + LAPLACIAN KERNEL\n",
    "plot_reads_long(\n",
    "        df_test_plot,\n",
    "        filters={\n",
    "            # \"gene_tss\": gene, \n",
    "            'group':['BT474_mV_high_Untreated',\n",
    "            'BT474_mV_low_Untreated',\n",
    "            'BT474_mV_Untreated_Unsorted']},\n",
    "        # facet_by='group',\n",
    "        color_by=\"locus_cluster\",\n",
    "        gene=gene,\n",
    "        hex_colors=hex_colors,\n",
    "        figsize=(12,6)\n",
    "    )\n",
    "\n",
    "#ISOLATING ONLY THE INTERESTING GROUPS FOR SUMMARY STATS\n",
    "# df_only_interesting_groups_PCA_euclidean = df_PCA_euclidean[df_PCA_euclidean.index.get_level_values('group').isin([\n",
    "#         'BT474_mV_high_Untreated',\n",
    "#         'BT474_mV_low_Untreated',\n",
    "#         'BT474_mV_Untreated_Unsorted'\n",
    "#     ])]\n",
    "\n",
    "# df_only_interesting_groups_PCA_euclidean = merge(df_only_interesting_groups_PCA_euclidean, df_dict_PCA_euclidean)\n",
    "# clusters_of_interest_PCA_euclidean = df_only_interesting_groups_PCA_euclidean['locus_cluster'].tolist() \n",
    "# summary(df_only_interesting_groups_PCA_euclidean, clusters_of_interest_PCA_euclidean, gene=gene)\n",
    "\n",
    "\n",
    "# COMPUTING THE GENE CENTROIDS TO PLOT AVERAGE PROFILES PER CLUSTER\n",
    "profiles_df, coverage_df, meta_df, positions= compute_gene_centroids(\n",
    "                                                                    df_used,\n",
    "                                                                    df_dict,\n",
    "                                                                    gene_tss=gene,\n",
    "                                                                   )\n",
    "\n",
    "# PLOTTING THE AVERAGE PROFILES PER CLUSTER FOR PCA + EUCLIDEAN + LAPLACIAN KERNEL\n",
    "plot_centroids_with_shading(\n",
    "    profiles_df,\n",
    "    positions,\n",
    "    meta_df_PCA_euclidean,\n",
    "    coverage_df,\n",
    "    hex_colors,\n",
    "    proportional_height=True,\n",
    "    smooth_sigma = 0,\n",
    "    title=gene + 'Average DNA Methylation Profiles per Cluster',\n",
    "    missingness_threshold=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dict_PCA_euclidean\n",
    "# GETTING THE DICTIONARY MAPPING CLUSTER TO COLOR\n",
    "cluster_to_color = {int(v[\"cluster\"]): v[\"color\"] for v in read_dict_PCA_euclidean.values()}\n",
    "cluster_to_color \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the order column for plotting purposes later\n",
    "df_test_plot_PCA_euclidean['order']=df_test_plot_PCA_euclidean['cluster']\n",
    "df_test_plot_PCA_euclidean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_single_molecule_occupancy(\n",
    "#     df,\n",
    "#     cluster_colors,                 # dict keyed by int cluster: {0:\"#...\",1:\"#...\",...}\n",
    "#     xlim=(-1000, 1000),\n",
    "#     point_size=3,\n",
    "#     figsize_cm=(12, 10),\n",
    "#     dpi=300\n",
    "# ):\n",
    "#     required = {\"readid\", \"C_start_shifted\", \"meth\", \"locus_cluster\", \"order\"}\n",
    "#     missing = required - set(df.columns)\n",
    "#     if missing:\n",
    "#         raise ValueError(f\"Missing columns: {', '.join(sorted(missing))}\")\n",
    "\n",
    "#     d = df.copy()\n",
    "\n",
    "#     # Unique (readid, order) → y positions\n",
    "#     per_read = (\n",
    "#         d[[\"readid\", \"order\"]]\n",
    "#         .dropna()\n",
    "#         .astype({\"order\": int})\n",
    "#         .sort_values(\"order\")\n",
    "#         .drop_duplicates(subset=\"readid\", keep=\"first\")\n",
    "#     )\n",
    "#     if per_read.empty:\n",
    "#         raise ValueError(\"No (readid, order) pairs available to assign y positions.\")\n",
    "\n",
    "#     y_map = dict(zip(per_read[\"readid\"], range(1, len(per_read) + 1)))\n",
    "#     d = d.loc[d[\"readid\"].isin(y_map)].copy()\n",
    "#     d[\"ypoint\"] = d[\"readid\"].map(y_map).astype(int) + 1\n",
    "#     d[\"C_start_shifted\"] = d[\"C_start_shifted\"].astype(float) + 1\n",
    "\n",
    "#     # Point colors: white for meth==1; else cluster color\n",
    "#     d[\"color\"] = np.where(\n",
    "#         d[\"meth\"] == 1,\n",
    "#         \"white\",\n",
    "#         [cluster_colors.get(int(c), \"black\") for c in d[\"locus_cluster\"]]\n",
    "#     )\n",
    "\n",
    "#     # Stripe color per read from its cluster\n",
    "#     stripes = (\n",
    "#         d[[\"readid\", \"ypoint\", \"locus_cluster\"]]\n",
    "#         .drop_duplicates(subset=\"readid\")\n",
    "#         .assign(stripe_color=lambda x: [cluster_colors.get(int(c), \"black\") for c in x[\"locus_cluster\"]])\n",
    "#     )\n",
    "\n",
    "#     # Plot\n",
    "#     w_in, h_in = (figsize_cm[0] / 2.54, figsize_cm[1] / 2.54)\n",
    "#     fig, ax = plt.subplots(figsize=(w_in, h_in), dpi=dpi)\n",
    "\n",
    "#     for _, row in stripes.iterrows():\n",
    "#         ax.hlines(y=row[\"ypoint\"], xmin=xlim[0], xmax=xlim[1],\n",
    "#                   colors=row[\"stripe_color\"], linewidth=2, alpha=1.0, zorder=0)\n",
    "\n",
    "#     ax.scatter(d[\"C_start_shifted\"], d[\"ypoint\"],\n",
    "#                s=point_size, c=d[\"color\"], marker=\"o\", linewidths=0, zorder=1)\n",
    "\n",
    "#     ax.set_xlim(*xlim)\n",
    "#     ax.set_xlabel(\"distance from motif\")\n",
    "#     ax.set_ylabel(\"\")\n",
    "#     ax.set_yticks([])\n",
    "#     for spine in (\"top\", \"right\", \"left\"):\n",
    "#         ax.spines[spine].set_visible(False)\n",
    "\n",
    "#     return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO PLOT SINGLE MOLECULE OCCUPANCY WITH ORDER-BASED STRIPE COLORS --TV PLOT \n",
    "#can work on loci specific (per genre) or on the whole dataframe (all genes)\n",
    "\n",
    "def plot_single_molecule_occupancy_rlike(\n",
    "    df,\n",
    "    cluster_colors,                 # dict keyed by int cluster: {1:\"#...\", 2:\"#...\", ..., 14:\"#...\"}\n",
    "    x_col=\"C_start_shifted\",\n",
    "    xlim=(-1000, 1000),\n",
    "    point_size=0.6,                 # ~ R cex=0.1; adjust for density\n",
    "    stripe_lw=2.0,\n",
    "    figsize_cm=(12, 10),\n",
    "    dpi=300,\n",
    "    n_clusters=14                   # number of orders/clusters\n",
    "):\n",
    "    required = {\"readid\", x_col, \"meth\", \"locus_cluster\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {', '.join(sorted(missing))}\")\n",
    "\n",
    "    d = df.copy()\n",
    "\n",
    "    # y positions: concatenate read IDs per order bucket\n",
    "    orders_present = sorted(d[\"locus_cluster\"].dropna().astype(int).unique())\n",
    "    readids_ordered = []\n",
    "    for o in orders_present:\n",
    "        ids_o = d.loc[d[\"locus_cluster\"] == o, \"readid\"].dropna().drop_duplicates().tolist()\n",
    "        readids_ordered.extend(ids_o)\n",
    "    if not readids_ordered:\n",
    "        raise ValueError(\"No read IDs available to assign y positions.\")\n",
    "\n",
    "    y_map = dict(zip(readids_ordered, range(1, len(readids_ordered) + 1)))\n",
    "    d = d.loc[d[\"readid\"].isin(y_map)].copy()\n",
    "    d[\"ypoint\"] = d[\"readid\"].map(y_map).astype(float) + 1.0  # R offset +1\n",
    "    d[x_col] = d[x_col].astype(float) + 1.0                   # R offset +1\n",
    "\n",
    "    # point colors: by cluster ( white for meth==1)\n",
    "    cluster_ids = d[\"locus_cluster\"].astype(int).to_numpy()\n",
    "    base_colors = np.array([cluster_colors.get(int(c), \"black\") for c in cluster_ids], dtype=object)\n",
    "    d[\"color\"] = np.where(d[\"meth\"] == 1, \"white\", base_colors)\n",
    "    \n",
    "\n",
    "    # stripe colors: order-based reversed cluster palette (if complete), else per-read cluster color\n",
    "    palette_list = [cluster_colors.get(i) for i in range(1, n_clusters + 1)]\n",
    "    if all(c is not None for c in palette_list):\n",
    "        reverse_colors = palette_list[::-1]  # order 1 gets last color, 14 gets first\n",
    "        stripes = (\n",
    "            d[[\"readid\", \"ypoint\", 'cluster']]\n",
    "            .drop_duplicates(subset=\"readid\")\n",
    "            .sort_values(\"locus_cluster\")\n",
    "        )\n",
    "        stripes[\"stripe_color\"] = [reverse_colors[int(o) - 1] for o in stripes[\"locus_cluster\"]]\n",
    "    else:\n",
    "        stripes = (\n",
    "            d[[\"readid\", \"ypoint\", \"locus_cluster\"]]\n",
    "            .drop_duplicates(subset=\"readid\")\n",
    "        )\n",
    "        stripes[\"stripe_color\"] = [cluster_colors.get(int(c), \"black\") for c in stripes[\"locus_cluster\"]]\n",
    "\n",
    "    # plot\n",
    "    w_in, h_in = (figsize_cm[0] / 2.54, figsize_cm[1] / 2.54)\n",
    "    fig, ax = plt.subplots(figsize=(w_in, h_in), dpi=dpi)\n",
    "\n",
    "    for _, row in stripes.iterrows():\n",
    "        ax.hlines(y=row[\"ypoint\"], xmin=xlim[0], xmax=xlim[1],\n",
    "                  colors=row[\"stripe_color\"], linewidth=stripe_lw, alpha=1.0, zorder=0)\n",
    "\n",
    "    ax.scatter(d[x_col], d[\"ypoint\"],\n",
    "               s=point_size, c=d[\"color\"], marker=\"o\", linewidths=0, zorder=1)\n",
    "\n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_xlabel(\"distance from motif\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_yticks([])\n",
    "    for spine in (\"top\", \"right\", \"left\"):\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_molecule_occupancy_rlike(\n",
    "    df=df_test_plot_PCA_euclidean,\n",
    "    cluster_colors=cluster_to_color,\n",
    "    xlim=(-1100, 1100),\n",
    "    stripe_lw=1.5,\n",
    "    point_size=0.6,\n",
    "    figsize_cm=(12, 5),\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_PCA_euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_df_PCA_euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_PCA_euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PCA_euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOW REPEATING THE WHOLE PROCESS FOR THE UNBINNED DATAFRAME\n",
    "# df_PCA_euclidean, X_PCA_euclidean_unbinned, partition_PCA_euclidean_unbinned, clusters_PCA_euclidean_unbinned, metrics_PCA_euclidean_unbinned = clustering_final(\n",
    "#         df_gene,\n",
    "#         n_neighbors=9,\n",
    "#         nan_threshold=0.1,\n",
    "#         nan_method='drop',\n",
    "#         scaling=False,\n",
    "#         pca_or_not=True,\n",
    "#         n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "#         metric='euclidean',          # 'euclidean' or 'cosine'\n",
    "#         transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "#         kernel_type='laplacian',\n",
    "#         leiden_resolution=0.8,\n",
    "#         seed=42\n",
    "#     )\n",
    "\n",
    "# read_dict_PCA_euclidean_unbinned = dict_id_cluster_color(df_gene_unbinned, clusters_PCA_euclidean_unbinned, hex_colors)\n",
    "\n",
    "# df_dict_PCA_euclidean_unbinned = dict_to_df(read_dict_PCA_euclidean_unbinned)\n",
    "# df_test_PCA_euclidean_unbinned= merge(df_proc, df_dict_PCA_euclidean_unbinned)\n",
    "\n",
    "# df_test_plot_PCA_euclidean_unbinned = preprocess_long_for_plot(df_test_PCA_euclidean_unbinned,\n",
    "#                                                           include_locus_cluster=True,\n",
    "#                                                           filter_outliers= True,\n",
    "#                                                           max_span_bp=None,     #i'm letting the filtering be based on the span_quantile\n",
    "#                                                           span_quantile=0.99,\n",
    "#                                                           require_center_inside=True,\n",
    "#                                                           min_cpg=1,\n",
    "#                                                           cpg_window_bp=5000\n",
    "#                                                           )\n",
    "\n",
    "\n",
    "# plot_reads_long(\n",
    "#         df_test_plot_PCA_euclidean_unbinned,\n",
    "#         filters={\n",
    "#             # \"gene_tss\": gene, \n",
    "#             'group':['BT474_mV_high_Untreated',\n",
    "#             'BT474_mV_low_Untreated',\n",
    "#             'BT474_mV_Untreated_Unsorted']},\n",
    "#         # facet_by='group',\n",
    "#         color_by=\"locus_cluster\",\n",
    "#         gene=gene,\n",
    "#         hex_colors=hex_colors,\n",
    "#         figsize =(12,5)\n",
    "#     )\n",
    "\n",
    "# plot_single_molecule_occupancy_rlike(\n",
    "#     df=df_test_plot_PCA_euclidean_unbinned,\n",
    "#     cluster_colors=cluster_to_color,\n",
    "#     xlim=(-1100, 1100),\n",
    "#     stripe_lw=1.5,\n",
    "#     point_size=0.6,\n",
    "#     figsize_cm=(12, 5),\n",
    "#     dpi=300\n",
    "# )\n",
    "\n",
    "# profiles_df_unbinned, coverage_df_unbinned_euclidean, meta_df_unbinned_euclidean, positions_unbinned_euclidean= compute_gene_centroids(\n",
    "#                                                                     df_gene_unbinned,\n",
    "#                                                                     df_dict_PCA_euclidean_unbinned,\n",
    "#                                                                     gene_tss='SETD1A_30958295_30958295',\n",
    "#                                                                    )\n",
    "\n",
    "# plot_centroids_with_shading(\n",
    "#     profiles_df_unbinned,\n",
    "#     positions_unbinned_euclidean,\n",
    "#     meta_df_unbinned_euclidean,\n",
    "#     coverage_df_unbinned_euclidean,\n",
    "#     hex_colors,\n",
    "#     smooth_sigma = 0,\n",
    "#     title=gene +'Average DNA Methylation Profiles per Cluster',\n",
    "#     missingness_threshold=0.5,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOOPING OVER ALL THE GENES AND PERFORMING THE WHOLE ANALYSIS PIPELINE -- PCA + EUCLIDEAN + LAPLACIAN KERNEL\n",
    "for i in range(len(gene_df)):\n",
    "    gene = gene_names[i]\n",
    "    df_gene = gene_df[i]\n",
    "\n",
    "    print(gene)\n",
    "\n",
    "    df_PCA_euclidean, X_PCA_euclidean, partition_PCA_euclidean, clusters_PCA_euclidean, metrics_PCA_euclidean = clustering_final(\n",
    "        df_gene,\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,\n",
    "        pca_or_not=True,\n",
    "        n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "        metric='euclidean',          # 'euclidean' or 'cosine' \n",
    "        transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=0.8,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # embedding_PCA_euclidean, fig_PCA_euclidean = plot_umap(\n",
    "    #     X_PCA_euclidean,\n",
    "    #     clusters_PCA_euclidean,\n",
    "    #     n_neighbors=25,\n",
    "    #     min_dist=0.1,\n",
    "    #     metric='euclidean',      \n",
    "    #     transform=None,          # None | 'logit' | 'arcsine' (use only if X are raw proportions)\n",
    "    #     n_pcs=None,              # set if X are raw features; None if X are already PCs\n",
    "    #     standardize=False,       # True if using raw features without PCA\n",
    "    #     seed=42,\n",
    "    #     palette=hex_colors,            # optional list/array or matplotlib colormap name\n",
    "    #     title=\"PCA + Euclidean + logit + Laplacian\",\n",
    "    #     gene=gene\n",
    "    # )\n",
    "\n",
    "    # print(metrics_PCA_euclidean)\n",
    "\n",
    "    # multi_sil_PCA_euclidean= silhouettes_multi(X_PCA_euclidean, clusters_PCA_euclidean, metric_main='euclidean', extra_metrics=['cosine', 'correlation', 'jaccard'])\n",
    "\n",
    "    # print(f\"Silhouette (PCA + Euclidean): {metrics_PCA_euclidean['silhouette']:.3f}\")\n",
    "    # print(f\"Silhouette (PCA + Euclidean) - Cosine: {multi_sil_PCA_euclidean['silhouette_cosine']:.3f}\")\n",
    "    # print(f\"Silhouette (PCA + Euclidean) - Correlation: {multi_sil_PCA_euclidean['silhouette_correlation']:.3f}\")\n",
    "    # print(f\"Silhouette (PCA + Euclidean) - Jaccard: {multi_sil_PCA_euclidean['silhouette_jaccard']:.3f}\")\n",
    "\n",
    "\n",
    "    read_dict_PCA_euclidean = dict_id_cluster_color(df_PCA_euclidean, clusters_PCA_euclidean, hex_colors)\n",
    "\n",
    "    df_dict_PCA_euclidean = dict_to_df(read_dict_PCA_euclidean)\n",
    "    df_test_PCA_euclidean= merge(df_proc, df_dict_PCA_euclidean)\n",
    "\n",
    "    # Long format for plotting\n",
    "    df_test_plot_PCA_euclidean = preprocess_long_for_plot(df_test_PCA_euclidean,\n",
    "                                                          include_locus_cluster=True,\n",
    "                                                          filter_outliers= True,\n",
    "                                                          max_span_bp=None,     #i'm letting the filtering be based on the span_quantile\n",
    "                                                          span_quantile=0.99,\n",
    "                                                          require_center_inside=True,\n",
    "                                                          min_cpg=1,\n",
    "                                                          cpg_window_bp=5000\n",
    "                                                          )\n",
    "\n",
    "    # Plot\n",
    "    plot_reads_long(\n",
    "        df_test_plot_PCA_euclidean,\n",
    "        filters={\n",
    "            # \"gene_tss\": gene, \n",
    "            'group':['BT474_mV_high_Untreated',\n",
    "            'BT474_mV_low_Untreated',\n",
    "            'BT474_mV_Untreated_Unsorted']},\n",
    "        # facet_by='group',\n",
    "        color_by=\"locus_cluster\",\n",
    "        gene=gene,\n",
    "        hex_colors=hex_colors\n",
    "    )\n",
    "\n",
    "    df_only_interesting_groups_PCA_euclidean = df_PCA_euclidean[df_PCA_euclidean.index.get_level_values('group').isin([\n",
    "        'BT474_mV_high_Untreated',\n",
    "        'BT474_mV_low_Untreated',\n",
    "        'BT474_mV_Untreated_Unsorted'\n",
    "    ])]\n",
    "\n",
    "    df_only_interesting_groups_PCA_euclidean = merge(df_only_interesting_groups_PCA_euclidean, df_dict_PCA_euclidean)\n",
    "    clusters_of_interest_PCA_euclidean = df_only_interesting_groups_PCA_euclidean['locus_cluster'].tolist() \n",
    "    # summary(df_only_interesting_groups_PCA_euclidean, clusters_of_interest_PCA_euclidean, gene=gene)\n",
    "\n",
    "    profiles_df_PCA_euclidean, coverage_df_PCA_euclidean, meta_df_PCA_euclidean, positions_PCA_euclidean= compute_gene_centroids(\n",
    "                                                                        df_PCA_euclidean,\n",
    "                                                                        df_dict_PCA_euclidean,\n",
    "                                                                        gene_tss=gene,\n",
    "                                                                    )\n",
    "\n",
    "    plot_centroids_with_shading(\n",
    "        profiles_df_PCA_euclidean,\n",
    "        positions_PCA_euclidean,\n",
    "        meta_df_PCA_euclidean,\n",
    "        coverage_df_PCA_euclidean,\n",
    "        hex_colors,\n",
    "        smooth_sigma = 0,\n",
    "        title= gene +':Average DNA Methylation Profiles per Cluster - EUCLIDEAN',\n",
    "        missingness_threshold=0.5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW LOOPING OVER ALL THE GENES AND PERFORMING THE WHOLE ANALYSIS PIPELINE -- NO PCA + COSINE + LAPLACIAN KERNEL\n",
    "for i in range(len(gene_df)):\n",
    "    gene = gene_names[i]\n",
    "    df_gene = gene_df[i]\n",
    "\n",
    "    print(gene)\n",
    "    df_cosine, X_cosine, partition_cosine, clusters_cosine, metrics_cosine = clustering_final(\n",
    "        df_gene,\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,\n",
    "        pca_or_not=False,\n",
    "        n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "        metric='cosine',          # 'euclidean' or 'cosine'\n",
    "        transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=0.8,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    embedding_cosine, fig_cosine = plot_umap(\n",
    "        X_cosine,\n",
    "        clusters_cosine,\n",
    "        n_neighbors=25,\n",
    "        min_dist=0.1,\n",
    "        metric='cosine',      # for Pipeline 2, use 'euclidean'\n",
    "        transform=None,          # None | 'logit' | 'arcsine' (use only if X are raw proportions)\n",
    "        n_pcs=None,              # set if X are raw features; None if X are already PCs\n",
    "        standardize=False,       # True if using raw features without PCA\n",
    "        seed=42,\n",
    "        palette=hex_colors,            # optional list/array or matplotlib colormap name\n",
    "        title=\"NO PCA + cosine + laplacian\",\n",
    "        gene=gene\n",
    "    )\n",
    "\n",
    "    # print(metrics_cosine)\n",
    "\n",
    "    # multi_sil_cosine= silhouettes_multi(X_cosine, clusters_cosine, metric_main='cosine', extra_metrics=['euclidean', 'correlation', 'jaccard'])\n",
    "\n",
    "    # print(f\"Silhouette (Cosine): {metrics_cosine['silhouette']:.3f}\")\n",
    "    # print(f\"Silhouette (Cosine) - Euclidean: {multi_sil_cosine['silhouette_euclidean']:.3f}\")\n",
    "    # print(f\"Silhouette (Cosine) - Correlation: {multi_sil_cosine['silhouette_correlation']:.3f}\")\n",
    "    # print(f\"Silhouette (Cosine) - Jaccard: {multi_sil_cosine['silhouette_jaccard']:.3f}\")\n",
    "\n",
    "\n",
    "    read_dict_cosine = dict_id_cluster_color(df_cosine, clusters_cosine, hex_colors)\n",
    "\n",
    "    df_dict_cosine = dict_to_df(read_dict_cosine)\n",
    "    df_test_cosine= merge(df_proc, df_dict_cosine)\n",
    "\n",
    "    # Long format for plotting\n",
    "    df_test_plot_cosine = preprocess_long_for_plot(df_test_cosine,\n",
    "                                                    include_locus_cluster=True,\n",
    "                                                    filter_outliers= True,\n",
    "                                                    max_span_bp=None,     #i'm letting the filtering be based on the span_quantile\n",
    "                                                    span_quantile=0.99,\n",
    "                                                    require_center_inside=True,\n",
    "                                                    min_cpg=1,\n",
    "                                                    cpg_window_bp=5000\n",
    "                                                    )\n",
    "\n",
    "    # Plot\n",
    "    plot_reads_long(\n",
    "        df_test_plot_cosine,\n",
    "        filters={\n",
    "            # \"gene_tss\": gene, \n",
    "            'group':['BT474_mV_high_Untreated',\n",
    "            'BT474_mV_low_Untreated',\n",
    "            'BT474_mV_Untreated_Unsorted']},\n",
    "        # facet_by='group',\n",
    "        color_by=\"locus_cluster\",\n",
    "        gene= gene,\n",
    "        hex_colors=hex_colors\n",
    "    )\n",
    "\n",
    "    df_only_interesting_groups_cosine = df_cosine[df_cosine.index.get_level_values('group').isin([\n",
    "        'BT474_mV_high_Untreated',\n",
    "        'BT474_mV_low_Untreated',\n",
    "        'BT474_mV_Untreated_Unsorted'\n",
    "    ])]\n",
    "\n",
    "    df_only_interesting_groups_cosine = merge(df_only_interesting_groups_cosine, df_dict_cosine)\n",
    "    clusters_of_interest_cosine = df_only_interesting_groups_cosine['locus_cluster'].tolist() \n",
    "    \n",
    "    summary(df_only_interesting_groups_cosine, clusters_of_interest_cosine)\n",
    "\n",
    "    profiles_df_cosine, coverage_df_cosine, meta_df_cosine, positions_cosine = compute_gene_centroids(\n",
    "                                                                        df_cosine,\n",
    "                                                                        df_dict_cosine,\n",
    "                                                                        gene_tss=gene,\n",
    "                                                                    )\n",
    "\n",
    "    plot_centroids_with_shading(\n",
    "        profiles_df_cosine,\n",
    "        positions_cosine,\n",
    "        meta_df_cosine,\n",
    "        coverage_df_cosine,\n",
    "        hex_colors,\n",
    "        smooth_sigma = 0,\n",
    "        title= gene + ' : Average DNA Methylation Profiles per Cluster - COSINE ',\n",
    "        missingness_threshold=0.5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW LOOPING OVER ALL THE GENES AND PERFORMING THE WHOLE ANALYSIS PIPELINE -- NO PCA + COSINE + LAPLACIAN KERNEL\n",
    "for i in range(len(gene_df)):\n",
    "    gene = gene_names[i]\n",
    "    df_gene = gene_df[i]\n",
    "\n",
    "    print(gene)\n",
    "\n",
    "    weights_pos = build_positional_weights(\n",
    "        columns=df_gene.columns,\n",
    "        window_bp=400,\n",
    "        center=0,\n",
    "        mode='gaussian',\n",
    "        inside_weight=1.0,\n",
    "        outside_weight=0.2,\n",
    "        sigma_bp=None,           # default window_bp/2\n",
    "        normalize_mean=True      # average weight ~ 1.0\n",
    "    )\n",
    "\n",
    "\n",
    "    df_cosine, X_cosine, part, clusters_cosine, metrics_cosine = clustering_final(\n",
    "        df_gene,\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,\n",
    "        pca_or_not=False,\n",
    "        n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "        metric='cosine',          # 'euclidean' or 'cosine'\n",
    "        transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=0.8,\n",
    "        seed=42,\n",
    "        pos_weights=weights_pos,    # <-- emphasize central bins\n",
    "        weight_stage='pre_pca'\n",
    "\n",
    "    )\n",
    "\n",
    "    partition_cosine = np.asarray(part.membership, dtype=int)\n",
    "\n",
    "    embedding_cosine, fig_cosine = plot_umap(\n",
    "        X_cosine,\n",
    "        clusters_cosine,\n",
    "        n_neighbors=25,\n",
    "        min_dist=0.1,\n",
    "        metric='cosine',      # for Pipeline 2, use 'euclidean'\n",
    "        transform=None,          # None | 'logit' | 'arcsine' (use only if X are raw proportions)\n",
    "        n_pcs=None,              # set if X are raw features; None if X are already PCs\n",
    "        standardize=False,       # True if using raw features without PCA\n",
    "        seed=42,\n",
    "        palette=hex_colors,            # optional list/array or matplotlib colormap name\n",
    "        title=\"NO PCA + cosine + laplacian\",\n",
    "        gene=gene\n",
    "    )\n",
    "\n",
    "    # print(metrics_cosine)\n",
    "\n",
    "    # multi_sil_cosine= silhouettes_multi(X_cosine, clusters_cosine, metric_main='cosine', extra_metrics=['euclidean', 'correlation', 'jaccard'])\n",
    "\n",
    "    # print(f\"Silhouette (Cosine): {metrics_cosine['silhouette']:.3f}\")\n",
    "    # print(f\"Silhouette (Cosine) - Euclidean: {multi_sil_cosine['silhouette_euclidean']:.3f}\")\n",
    "    # print(f\"Silhouette (Cosine) - Correlation: {multi_sil_cosine['silhouette_correlation']:.3f}\")\n",
    "    # print(f\"Silhouette (Cosine) - Jaccard: {multi_sil_cosine['silhouette_jaccard']:.3f}\")\n",
    "\n",
    "\n",
    "    read_dict_cosine = dict_id_cluster_color(df_cosine, clusters_cosine, hex_colors)\n",
    "\n",
    "    df_dict_cosine = dict_to_df(read_dict_cosine)\n",
    "    df_test_cosine= merge(df_proc, df_dict_cosine)\n",
    "\n",
    "    # Long format for plotting\n",
    "    df_test_plot_cosine = preprocess_long_for_plot(df_test_cosine,\n",
    "                                                    include_locus_cluster=True,\n",
    "                                                    filter_outliers= True,\n",
    "                                                    max_span_bp=None,     #i'm letting the filtering be based on the span_quantile\n",
    "                                                    span_quantile=0.99,\n",
    "                                                    require_center_inside=True,\n",
    "                                                    min_cpg=1,\n",
    "                                                    cpg_window_bp=5000\n",
    "                                                    )\n",
    "\n",
    "    # Plot\n",
    "    plot_reads_long(\n",
    "        df_test_plot_cosine,\n",
    "        filters={\n",
    "            # \"gene_tss\": gene, \n",
    "            'group':['BT474_mV_high_Untreated',\n",
    "            'BT474_mV_low_Untreated',\n",
    "            'BT474_mV_Untreated_Unsorted']},\n",
    "        # facet_by='group',\n",
    "        color_by=\"locus_cluster\",\n",
    "        gene= gene,\n",
    "        hex_colors=hex_colors\n",
    "    )\n",
    "\n",
    "    df_only_interesting_groups_cosine = df_cosine[df_cosine.index.get_level_values('group').isin([\n",
    "        'BT474_mV_high_Untreated',\n",
    "        'BT474_mV_low_Untreated',\n",
    "        'BT474_mV_Untreated_Unsorted'\n",
    "    ])]\n",
    "\n",
    "    df_only_interesting_groups_cosine = merge(df_only_interesting_groups_cosine, df_dict_cosine)\n",
    "    clusters_of_interest_cosine = df_only_interesting_groups_cosine['locus_cluster'].tolist() \n",
    "    \n",
    "    summary(df_only_interesting_groups_cosine, clusters_of_interest_cosine)\n",
    "\n",
    "    profiles_df_cosine, coverage_df_cosine, meta_df_cosine, positions_cosine = compute_gene_centroids(\n",
    "                                                                        df_cosine,\n",
    "                                                                        df_dict_cosine,\n",
    "                                                                        gene_tss=gene,\n",
    "                                                                    )\n",
    "\n",
    "    plot_centroids_with_shading(\n",
    "        profiles_df_cosine,\n",
    "        positions_cosine,\n",
    "        meta_df_cosine,\n",
    "        coverage_df_cosine,\n",
    "        hex_colors,\n",
    "        smooth_sigma = 0,\n",
    "        title= gene + ' : Average DNA Methylation Profiles per Cluster - COSINE ',\n",
    "        missingness_threshold=0.5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine, X_cosine, partition_cosine, clusters_cosine, metrics_cosine = clustering_final(\n",
    "        gene_df[14],\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='impute',\n",
    "        scaling=False,\n",
    "        pca_or_not=False,\n",
    "        n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "        metric='cosine',          # 'euclidean' or 'cosine'\n",
    "        transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=0.8,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "embedding_cosine, fig_cosine = plot_umap(\n",
    "        X_cosine,\n",
    "        clusters_cosine,\n",
    "        n_neighbors=25,\n",
    "        min_dist=0.1,\n",
    "        metric='cosine',      # for Pipeline 2, use 'euclidean'\n",
    "        transform=None,          # None | 'logit' | 'arcsine' (use only if X are raw proportions)\n",
    "        n_pcs=None,              # set if X are raw features; None if X are already PCs\n",
    "        standardize=False,       # True if using raw features without PCA\n",
    "        seed=42,\n",
    "        palette=hex_colors,            # optional list/array or matplotlib colormap name\n",
    "        title=\"NO PCA + cosine + laplacian\",\n",
    "        gene= gene_names[14]\n",
    "    )\n",
    "\n",
    "print(metrics_cosine)\n",
    "\n",
    "# multi_sil_cosine= silhouettes_multi(X_cosine, clusters_cosine, metric_main='cosine', extra_metrics=['euclidean', 'correlation', 'jaccard'])\n",
    "\n",
    "# print(f\"Silhouette (Cosine): {metrics_cosine['silhouette']:.3f}\")\n",
    "# print(f\"Silhouette (Cosine) - Euclidean: {multi_sil_cosine['silhouette_euclidean']:.3f}\")\n",
    "# print(f\"Silhouette (Cosine) - Correlation: {multi_sil_cosine['silhouette_correlation']:.3f}\")\n",
    "# print(f\"Silhouette (Cosine) - Jaccard: {multi_sil_cosine['silhouette_jaccard']:.3f}\")\n",
    "\n",
    "\n",
    "read_dict_cosine = dict_id_cluster_color(df_cosine, clusters_cosine, hex_colors)\n",
    "\n",
    "df_dict_cosine = dict_to_df(read_dict_cosine)\n",
    "df_test_cosine= merge(df_proc, df_dict_cosine)\n",
    "\n",
    "profiles_df_cos, coverage_df, meta_df, positions = compute_gene_centroids(\n",
    "    df_reads=df_cosine,        # reads × bins methylation matrix\n",
    "    df_map=df_dict_cosine,        # mapping of readid → cluster + color\n",
    "    gene_tss= gene_names[14],\n",
    "    extra_meta_cols=['gene_tss', 'group', 'cluster']  # add other non-bin columns here if present\n",
    ")\n",
    "\n",
    "profiles_df_gene, coverage_df_gene, meta_df_gene, positions_gene = compute_gene_centroids(\n",
    "    df_reads= gene_df[14],        # reads × bins methylation matrix\n",
    "    df_map=df_dict_cosine,        # mapping of readid → cluster + color\n",
    "    gene_tss= gene_names[14],\n",
    "    extra_meta_cols=['gene_tss', 'group', 'cluster']  # add other non-bin columns here if present\n",
    ")\n",
    "\n",
    "plot_centroids_with_shading(\n",
    "    profiles_df_cos,\n",
    "    positions,\n",
    "    meta_df,\n",
    "    coverage_df,\n",
    "    hex_colors,\n",
    "    smooth_sigma = 0,\n",
    "    title='Average DNA Methylation Profiles per Cluster',\n",
    "    missingness_threshold=0.5,\n",
    ")\n",
    "\n",
    "plot_centroids_with_shading(\n",
    "    profiles_df_gene,\n",
    "    positions_gene,\n",
    "    meta_df_gene,\n",
    "    coverage_df_gene,\n",
    "    hex_colors,\n",
    "    smooth_sigma = 0,\n",
    "    title='Average DNA Methylation Profiles per Cluster',\n",
    "    missingness_threshold=0.5,\n",
    ")\n",
    "\n",
    "gene_df[14].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_cosine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bulk has columns: ['cluster','C_pos','meth','cov'] for the whole dataset\n",
    "\n",
    "P_df, coverage_bulk_df, meta_bulk_df, positions_bulk = compute_bulk_centroids(df_bulk, use_cov_for_proportion=True)\n",
    "\n",
    "fig, axes = plot_centroids_with_shading(\n",
    "    P_df=P_df,\n",
    "    positions=positions_bulk,\n",
    "    meta_df=meta_bulk_df,\n",
    "    hex_colors=hex_colors,\n",
    "    title=\"Average DNA Methylation Profiles per Cluster (Bulk)\"\n",
    ")\n",
    "\n",
    "P_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_bulk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bulk has columns: ['cluster','C_pos','meth','cov'] for the whole dataset\n",
    "\n",
    "fig, axes = plot_centroids_with_shading(\n",
    "    P_df=profiles_df_bulk_binned,\n",
    "    positions=positions_bulk_binned,\n",
    "    meta_df=meta_df_bulk_binned, #attention ici, j'utilise pas le meta donné par la fonction compute_gene_centroid\n",
    "    hex_colors=hex_colors,\n",
    "    title=\"Average DNA Methylation Profiles per Cluster (Bulk) (Binned)\",\n",
    "    proportional_height=False\n",
    ")\n",
    "\n",
    "profiles_df_bulk_binned.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dict_bulk = dict_id_cluster_color(df_cosine, clusters_cosine, hex_colors)\n",
    "\n",
    "df_dict_cosine = dict_to_df(read_dict_cosine)\n",
    "df_test_cosine= merge(df_proc, df_dict_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_array = profiles_df_bulk_binned.to_numpy(float)\n",
    "\n",
    "# Optional per-bin weights for cosine\n",
    "# weights = coverage_df.sum(axis=0).to_numpy(float) / (coverage_df.sum(axis=0).mean() + 1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_df, S, D = assign_gene_clusters_to_consensus(\n",
    "    G=profiles_df,               # DataFrame (rows = gene clusters, cols = common positions)\n",
    "    meta=meta_df,         # aligned to G rows\n",
    "    P=profiles_df_bulk_binned,               # DataFrame (rows = bulk clusters, cols = common positions)\n",
    "    method='cosine',\n",
    "    center_rows=True,\n",
    "    # weights=weights,  # optional pd.Series indexed by common positions\n",
    "    min_overlap=10,\n",
    "    min_similarity=0,\n",
    "    allow_unassigned=True,\n",
    "    capacity_per_type=1,\n",
    ")\n",
    "\n",
    "assign_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_for_assign = meta_df[['gene_tss', 'cluster_id', 'n_reads']].rename(columns={'n_reads': 'size'})\n",
    "\n",
    "# 2) Heatmap for one gene\n",
    "fig, ax = plot_gene_mapping_heatmap(\n",
    "    assign_df=assign_df,\n",
    "    S=S,\n",
    "    meta=meta_for_assign,\n",
    "    P=profiles_df_bulk_binned,\n",
    "    gene_id= gene_names[14],\n",
    "    sort_rows=False\n",
    ")\n",
    "\n",
    "# 3) Assignment summary across genes\n",
    "# fig2, ax2 = plot_assignment_summary(assign_df)\n",
    "\n",
    "# 4) Recolor meta for plotting centroids\n",
    "bulk_color_map = {int(row['cluster_id']): row['cluster_color']\n",
    "                     for _, row in meta_bulk_df.iterrows()}  # build from bulk meta\n",
    "meta_colored = recolor_meta_by_bulk(assign_df, meta_df, bulk_color_map, gene_id=gene_names[14])\n",
    "\n",
    "# 5) Assignment confidence\n",
    "# fig3, ax3 = plot_assignment_confidence(assign_df, gene_id=gene)\n",
    "\n",
    "plot_centroids_with_shading(\n",
    "    profiles_df_gene,\n",
    "    positions_gene,\n",
    "    meta_colored,\n",
    "    coverage_df_gene,\n",
    "    hex_colors,\n",
    "    smooth_sigma = 0,\n",
    "    title='Average DNA Methylation Profiles per Cluster',\n",
    "    missingness_threshold=0.5,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build positional weights emphasizing +/- 500 bp around Pol2 (center=0)\n",
    "weights_pos = build_positional_weights(columns=P_df.columns, window_bp=200, center=0, mode='gaussian',\n",
    "                                       inside_weight=1.0, outside_weight=0.5, normalize_mean=True)\n",
    "\n",
    "# Option A: Cosine with positional weights (no PCA, masked cosine):\n",
    "assign_weighted_df, S, D = assign_gene_clusters_to_consensus(\n",
    "    G=profiles_df,\n",
    "    meta=meta_df,\n",
    "    P=profiles_df_bulk_binned,\n",
    "    method='cosine',\n",
    "    center_rows=True,            # keep raw levels; set True for pattern-only\n",
    "    weights=weights_pos,          # emphasize +/- 500 bp region\n",
    "    min_overlap=10,               # ensure enough shared bins\n",
    "    min_similarity=0,           # allow 'unassigned' if below threshold\n",
    "    allow_unassigned=True,\n",
    "    capacity_per_type=1\n",
    ")\n",
    "\n",
    "assign_weighted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_for_assign_weighted = meta_df[['gene_tss', 'cluster_id', 'n_reads']].rename(columns={'n_reads': 'size'})\n",
    "# 2) Heatmap for one gene\n",
    "fig, ax = plot_gene_mapping_heatmap(\n",
    "    assign_df=assign_weighted_df,\n",
    "    S=S,\n",
    "    meta=meta_for_assign_weighted,\n",
    "    P=profiles_df_bulk_binned,\n",
    "    gene_id=gene_names[14],\n",
    "    sort_rows=False\n",
    ")\n",
    "\n",
    "# 3) Assignment summary across genes\n",
    "# fig2, ax2 = plot_assignment_summary(assign_weighted_df)\n",
    "\n",
    "# 4) Recolor meta for plotting centroids\n",
    "bulk_color_map = {cons_id: '#hexcolor' for cons_id in P_df.index}  # build from bulk meta\n",
    "meta_colored = recolor_meta_by_bulk(assign_weighted_df, meta_df, bulk_color_map, gene_id=gene)\n",
    "\n",
    "# 5) Assignment confidence\n",
    "# fig3, ax3 = plot_assignment_confidence(assign_df, gene_id=gene)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colours = [\n",
    "#     \"#FF9999\",  # warm soft red\n",
    "#     \"#FFB380\",  # coral orange\n",
    "#     \"#FFE680\",  # golden pastel yellow\n",
    "#     \"#A8E6CF\",  # mint green\n",
    "#     \"#81C7F5\",  # light sky blue\n",
    "#     \"#9FA8DA\",  # soft indigo blue\n",
    "#     \"#CBA3E3\",  # lavender purple\n",
    "#     \"#FF9EC4\",  # rose pink\n",
    "#     \"#FFBC8A\",  # peach apricot\n",
    "#     \"#7FD1AE\",  # seafoam green\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = [\n",
    "    \"#969494\",\n",
    "    \"#969494\",\n",
    "    \"#969494\",\n",
    "    \"#969494\",\n",
    "    \"#969494\",\n",
    "    \"#969494\",\n",
    "    \"#969494\",\n",
    "    \"#969494\",\n",
    "    \"#969494\",\n",
    "    \"#969494\",\n",
    "    \"#969494\"\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UNWEIGTHED CLUSTERING + UNWEIGHTED ASSIGNMENT LOOP OVER ALL GENES\n",
    "P_array = profiles_df_bulk_binned.to_numpy(float)\n",
    "print(len(gene_df))\n",
    "sim=[]\n",
    "for i in range(len(gene_df)):\n",
    "    gene = gene_names[i]\n",
    "    df_gene = gene_df[i]\n",
    "\n",
    "    df_cosine, X_cosine, partition_cosine, clusters_cosine, metrics_cosine = clustering_final(\n",
    "        df_gene,\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,\n",
    "        pca_or_not=False,\n",
    "        n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "        metric='cosine',          # 'euclidean' or 'cosine'\n",
    "        transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=0.8,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    read_dict_cosine = dict_id_cluster_color(df_cosine, clusters_cosine, colours)\n",
    "    df_dict_cosine = dict_to_df(read_dict_cosine)\n",
    "    df_test_cosine= merge(df_proc, df_dict_cosine)\n",
    "\n",
    "    profiles_df, coverage_df, meta_df, positions = compute_gene_centroids(\n",
    "    df_reads=df_gene,        # reads × bins methylation matrix\n",
    "    df_map=df_dict_cosine,        # mapping of readid → cluster + color\n",
    "    gene_tss= gene,\n",
    "    extra_meta_cols=['gene_tss', 'group', 'cluster']  # add other non-bin columns here if present\n",
    ")\n",
    "\n",
    "    Gc = _coerce_sort(profiles_df)\n",
    "    Pc = _coerce_sort(profiles_df_bulk_binned)\n",
    "    common = np.intersect1d(Gc.columns.values, Pc.columns.values)\n",
    "\n",
    "    assign_df, S, D = assign_gene_clusters_to_consensus(\n",
    "        G=Gc,               # DataFrame (rows = gene clusters, cols = common positions)\n",
    "        meta=meta_df,         # aligned to G rows\n",
    "        P=Pc,               # DataFrame (rows = bulk clusters, cols = common positions)\n",
    "        method='cosine',\n",
    "        center_rows=True,\n",
    "        weights=None,  # optional pd.Series indexed by common positions\n",
    "        min_overlap=20,\n",
    "        min_similarity=0.5,\n",
    "        allow_unassigned=True,\n",
    "        capacity_per_type=1,\n",
    "    )\n",
    "\n",
    "    meta_for_assign = meta_df[['gene_tss', 'cluster_id', 'n_reads']].rename(columns={'n_reads': 'size'})\n",
    "\n",
    "    fig, ax = plot_gene_mapping_heatmap(\n",
    "        assign_df=assign_df,\n",
    "        S=S,\n",
    "        meta=meta_for_assign,\n",
    "        P=Pc,\n",
    "        gene_id=gene,\n",
    "        sort_rows=False\n",
    "    )\n",
    "\n",
    "    bulk_color_map = {int(row['cluster_id']): row['cluster_color']\n",
    "                     for _, row in meta_bulk_df.iterrows()}  # build from bulk meta\n",
    "    \n",
    "    meta_colored = recolor_meta_by_bulk(assign_df, meta_df, bulk_color_map, gene_id= gene)\n",
    "\n",
    "    # print(meta_colored)\n",
    "\n",
    "    plot_centroids_with_shading(\n",
    "        profiles_df,\n",
    "        positions,\n",
    "        meta_colored,\n",
    "        coverage_df,\n",
    "        hex_colors,\n",
    "        proportional_height=False,\n",
    "        smooth_sigma = 0,\n",
    "        title= gene + ' Average DNA Methylation Profiles per Cluster - reassigned colors - unweighted clustering - unweighted assignment',\n",
    "        missingness_threshold=0.5,\n",
    "    )\n",
    "\n",
    "    print( assign_df['similarity'].mean())\n",
    "    sim.append(assign_df['similarity'].mean())\n",
    "\n",
    "print(np.mean(sim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "##UNWEITHED CLUSTERING + WEIGHTED BOX ASSIGNMENT LOOP OVER ALL GENES\n",
    "P_array = profiles_df_bulk_binned.to_numpy(float)\n",
    "\n",
    "sim=[]\n",
    "for i in range(len(gene_df)):\n",
    "    gene = gene_names[i]\n",
    "    df_gene = gene_df[i]\n",
    "\n",
    "\n",
    "    df_cosine, X_cosine, part, clusters_cosine, metrics_cosine = clustering_final(\n",
    "        df_gene,\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,\n",
    "        pca_or_not=False,\n",
    "        n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "        metric='cosine',          # 'euclidean' or 'cosine'\n",
    "        transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=0.8,\n",
    "        seed=42,\n",
    "        pos_weights=None,    # <-- emphasize central bins\n",
    "        weight_stage=None\n",
    "\n",
    "    )\n",
    "    \n",
    "    read_dict_cosine = dict_id_cluster_color(df_cosine, clusters_cosine, colours)\n",
    "    df_dict_cosine = dict_to_df(read_dict_cosine)\n",
    "    df_test_cosine= merge(df_proc, df_dict_cosine)\n",
    "\n",
    "    profiles_df, coverage_df, meta_df, positions = compute_gene_centroids(\n",
    "    df_reads=df_gene,        # reads × bins methylation matrix\n",
    "    df_map=df_dict_cosine,        # mapping of readid → cluster + color\n",
    "    gene_tss= gene,\n",
    "    extra_meta_cols=['gene_tss', 'group', 'cluster']  # add other non-bin columns here if present\n",
    ")\n",
    "    \n",
    "    # Build weights AFTER columns are coerced/sorted and intersection computed\n",
    "    Gc = _coerce_sort(profiles_df)\n",
    "    Pc = _coerce_sort(profiles_df_bulk_binned)\n",
    "    common = np.intersect1d(Gc.columns.values, Pc.columns.values)\n",
    "\n",
    "    weights_pos = build_positional_weights(\n",
    "    columns=common,      # use the intersection, not P_df.columns\n",
    "    window_bp=400,\n",
    "    center=0,\n",
    "    mode='box',\n",
    "    inside_weight=1.0,\n",
    "    outside_weight=0.5,\n",
    "    normalize_mean=True\n",
    ")\n",
    "    assign_weighted_df, S, D = assign_gene_clusters_to_consensus(\n",
    "    G=Gc,\n",
    "    meta=meta_df,\n",
    "    P=Pc,\n",
    "    method='cosine',\n",
    "    center_rows=True,            # keep raw levels; set True for pattern-only\n",
    "    weights=weights_pos,          # emphasize +/- 500 bp region\n",
    "    min_overlap=20,               # ensure enough shared bins\n",
    "    min_similarity=0.5,           # allow 'unassigned' if below threshold\n",
    "    allow_unassigned=True,\n",
    "    capacity_per_type=1\n",
    ")\n",
    "\n",
    "    meta_for_assign = meta_df[['gene_tss', 'cluster_id', 'n_reads']].rename(columns={'n_reads': 'size'})\n",
    "\n",
    "    fig, ax = plot_gene_mapping_heatmap(\n",
    "        assign_df=assign_weighted_df,\n",
    "        S=S,\n",
    "        meta=meta_for_assign,\n",
    "        P=Pc,\n",
    "        gene_id=gene,\n",
    "        sort_rows=False\n",
    "    )\n",
    "\n",
    "    bulk_color_map = {int(row['cluster_id']): row['cluster_color']\n",
    "                     for _, row in meta_bulk_df.iterrows()}  # build from bulk meta\n",
    "    \n",
    "    meta_colored = recolor_meta_by_bulk(assign_weighted_df, meta_df, bulk_color_map, gene_id= gene)\n",
    "\n",
    "    # print(meta_colored)\n",
    "\n",
    "    plot_centroids_with_shading(\n",
    "        profiles_df,\n",
    "        positions,\n",
    "        meta_colored,\n",
    "        coverage_df,\n",
    "        hex_colors,\n",
    "        proportional_height=False,\n",
    "        smooth_sigma = 0,\n",
    "        title= gene + ' Average DNA Methylation Profiles per Cluster - reassigned colors - unweighted clustering - weighted box assignment',\n",
    "        missingness_threshold=0.5,\n",
    "    )\n",
    "\n",
    "    print( assign_weighted_df['similarity'].mean())\n",
    "    sim.append(assign_weighted_df['similarity'].mean())\n",
    "\n",
    "print(np.mean(sim))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UNWEIGHTED CLUSTERING + WEIGHTED GAUSSIAN ASSIGNMENT LOOP OVER ALL GENES\n",
    "P_array = profiles_df_bulk_binned.to_numpy(float)\n",
    "\n",
    "sim=[]\n",
    "\n",
    "for i in range(len(gene_df)):\n",
    "    gene = gene_names[i]\n",
    "    df_gene = gene_df[i]\n",
    "\n",
    "\n",
    "    df_cosine, X_cosine, part, clusters_cosine, metrics_cosine = clustering_final(\n",
    "        df_gene,\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,\n",
    "        pca_or_not=False,\n",
    "        n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "        metric='cosine',          # 'euclidean' or 'cosine'\n",
    "        transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=0.8,\n",
    "        seed=42,\n",
    "        pos_weights=None,    # <-- emphasize central bins\n",
    "        weight_stage=None\n",
    "\n",
    "    )\n",
    "    \n",
    "    read_dict_cosine = dict_id_cluster_color(df_cosine, clusters_cosine, colours)\n",
    "    df_dict_cosine = dict_to_df(read_dict_cosine)\n",
    "    df_test_cosine= merge(df_proc, df_dict_cosine)\n",
    "\n",
    "    profiles_df, coverage_df, meta_df, positions = compute_gene_centroids(\n",
    "    df_reads=df_gene,        # reads × bins methylation matrix\n",
    "    df_map=df_dict_cosine,        # mapping of readid → cluster + color\n",
    "    gene_tss= gene,\n",
    "    extra_meta_cols=['gene_tss', 'group', 'cluster']  # add other non-bin columns here if present\n",
    ")\n",
    "    \n",
    "    # Build weights AFTER columns are coerced/sorted and intersection computed\n",
    "    Gc = _coerce_sort(profiles_df)\n",
    "    Pc = _coerce_sort(profiles_df_bulk_binned)\n",
    "    common = np.intersect1d(Gc.columns.values, Pc.columns.values)\n",
    "\n",
    "    weights_pos = build_positional_weights(\n",
    "    columns=common,      # use the intersection, not P_df.columns\n",
    "    window_bp=400,\n",
    "    center=0,\n",
    "    mode='gaussian',\n",
    "    inside_weight=1.0,\n",
    "    outside_weight=0.2,\n",
    "    normalize_mean=True\n",
    ")\n",
    "    assign_weighted_df, S, D = assign_gene_clusters_to_consensus(\n",
    "    G=Gc,\n",
    "    meta=meta_df,\n",
    "    P=Pc,\n",
    "    method='cosine',\n",
    "    center_rows=True,            # keep raw levels; set True for pattern-only\n",
    "    weights=weights_pos,          # emphasize +/- 500 bp region\n",
    "    min_overlap=20,               # ensure enough shared bins\n",
    "    min_similarity=0.5,           # allow 'unassigned' if below threshold\n",
    "    allow_unassigned=True,\n",
    "    capacity_per_type=1\n",
    ")\n",
    "\n",
    "    meta_for_assign = meta_df[['gene_tss', 'cluster_id', 'n_reads']].rename(columns={'n_reads': 'size'})\n",
    "\n",
    "    fig, ax = plot_gene_mapping_heatmap(\n",
    "        assign_df=assign_weighted_df,\n",
    "        S=S,\n",
    "        meta=meta_for_assign,\n",
    "        P=Pc,\n",
    "        gene_id=gene,\n",
    "        sort_rows=False\n",
    "    )\n",
    "\n",
    "    bulk_color_map = {int(row['cluster_id']): row['cluster_color']\n",
    "                     for _, row in meta_bulk_df.iterrows()}  # build from bulk meta\n",
    "    \n",
    "    meta_colored = recolor_meta_by_bulk(assign_weighted_df, meta_df, bulk_color_map, gene_id= gene)\n",
    "\n",
    "    # print(meta_colored)\n",
    "\n",
    "    plot_centroids_with_shading(\n",
    "        profiles_df,\n",
    "        positions,\n",
    "        meta_colored,\n",
    "        coverage_df,\n",
    "        hex_colors,\n",
    "        proportional_height=False,\n",
    "        smooth_sigma = 0,\n",
    "        title= gene + ' Average DNA Methylation Profiles per Cluster - reassigned colors - unweighted clustering - weighted gaussian assignment',\n",
    "        missingness_threshold=0.5,\n",
    "    )\n",
    "    print( assign_weighted_df['similarity'].mean())\n",
    "    sim.append(assign_weighted_df['similarity'].mean())\n",
    "\n",
    "print(np.mean(sim))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WEIGHTED CLUSTERING + UNWEIGHTED ASSIGNMENT LOOP OVER ALL GENES\n",
    "P_array = profiles_df_bulk_binned.to_numpy(float)\n",
    "sim=[]\n",
    "for i in range(len(gene_df)):\n",
    "    gene = gene_names[i]\n",
    "    df_gene = gene_df[i]\n",
    "\n",
    "    weights_pos = build_positional_weights(\n",
    "        columns=df_gene.columns,\n",
    "        window_bp=400,\n",
    "        center=0,\n",
    "        mode='gaussian',\n",
    "        inside_weight=1.0,\n",
    "        outside_weight=0.2,\n",
    "        sigma_bp=None,           # default window_bp/2\n",
    "        normalize_mean=True      # average weight ~ 1.0\n",
    "    )\n",
    "\n",
    "\n",
    "    df_cosine, X_cosine, part, clusters_cosine, metrics_cosine = clustering_final(\n",
    "        df_gene,\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,\n",
    "        pca_or_not=False,\n",
    "        n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "        metric='cosine',          # 'euclidean' or 'cosine'\n",
    "        transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=0.8,\n",
    "        seed=42,\n",
    "        pos_weights=weights_pos,    # <-- emphasize central bins\n",
    "        weight_stage='post_pca'\n",
    "\n",
    "    )\n",
    "    \n",
    "    read_dict_cosine = dict_id_cluster_color(df_cosine, clusters_cosine, colours)\n",
    "    df_dict_cosine = dict_to_df(read_dict_cosine)\n",
    "    df_test_cosine= merge(df_proc, df_dict_cosine)\n",
    "\n",
    "    profiles_df, coverage_df, meta_df, positions = compute_gene_centroids(\n",
    "    df_reads=df_gene,        # reads × bins methylation matrix\n",
    "    df_map=df_dict_cosine,        # mapping of readid → cluster + color\n",
    "    gene_tss= gene,\n",
    "    extra_meta_cols=['gene_tss', 'group', 'cluster']  # add other non-bin columns here if present\n",
    ")\n",
    "    \n",
    "    # Build weights AFTER columns are coerced/sorted and intersection computed\n",
    "    Gc = _coerce_sort(profiles_df)\n",
    "    Pc = _coerce_sort(profiles_df_bulk_binned)\n",
    "    common = np.intersect1d(Gc.columns.values, Pc.columns.values)\n",
    "\n",
    "#     weights_pos = build_positional_weights(\n",
    "#     columns=common,      # use the intersection, not P_df.columns\n",
    "#     window_bp=400,\n",
    "#     center=0,\n",
    "#     mode='box',\n",
    "#     inside_weight=1.0,\n",
    "#     outside_weight=0.5,\n",
    "#     normalize_mean=True\n",
    "# )\n",
    "    assign_weighted_df, S, D = assign_gene_clusters_to_consensus(\n",
    "    G=Gc,\n",
    "    meta=meta_df,\n",
    "    P=Pc,\n",
    "    method='cosine',\n",
    "    center_rows=True,            # keep raw levels; set True for pattern-only\n",
    "    weights=None,          # emphasize +/- 500 bp region\n",
    "    min_overlap=20,               # ensure enough shared bins\n",
    "    min_similarity=0.5,           # allow 'unassigned' if below threshold\n",
    "    allow_unassigned=True,\n",
    "    capacity_per_type=1\n",
    ")\n",
    "\n",
    "    meta_for_assign = meta_df[['gene_tss', 'cluster_id', 'n_reads']].rename(columns={'n_reads': 'size'})\n",
    "\n",
    "    fig, ax = plot_gene_mapping_heatmap(\n",
    "        assign_df=assign_weighted_df,\n",
    "        S=S,\n",
    "        meta=meta_for_assign,\n",
    "        P=Pc,\n",
    "        gene_id=gene,\n",
    "        sort_rows=False\n",
    "    )\n",
    "\n",
    "    bulk_color_map = {int(row['cluster_id']): row['cluster_color']\n",
    "                     for _, row in meta_bulk_df.iterrows()}  # build from bulk meta\n",
    "    \n",
    "    meta_colored = recolor_meta_by_bulk(assign_weighted_df, meta_df, bulk_color_map, gene_id= gene)\n",
    "\n",
    "    # print(meta_colored)\n",
    "\n",
    "    plot_centroids_with_shading(\n",
    "        profiles_df,\n",
    "        positions,\n",
    "        meta_colored,\n",
    "        coverage_df,\n",
    "        hex_colors,\n",
    "        proportional_height=False,\n",
    "        smooth_sigma = 0,\n",
    "        title= gene + ' Average DNA Methylation Profiles per Cluster - reassigned colors - weighted clustering - unweighted assignment',\n",
    "        missingness_threshold=0.5,\n",
    "    )\n",
    "\n",
    "    print( assign_weighted_df['similarity'].mean())\n",
    "    sim.append(assign_weighted_df['similarity'].mean())\n",
    "\n",
    "print(np.mean(sim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WEIGHTED CLUSTERING + WEIGHTED GAUSSIAN ASSIGNMENT LOOP OVER ALL GENES\n",
    "P_array = profiles_df_bulk_binned.to_numpy(float)\n",
    "sim=[]\n",
    "for i in range(len(gene_df)):\n",
    "    gene = gene_names[i]\n",
    "    df_gene = gene_df[i]\n",
    "\n",
    "    weights_pos = build_positional_weights(\n",
    "        columns=df_gene.columns,\n",
    "        window_bp=400,\n",
    "        center=0,\n",
    "        mode='gaussian',\n",
    "        inside_weight=1.0,\n",
    "        outside_weight=0.2,\n",
    "        sigma_bp=None,           # default window_bp/2\n",
    "        normalize_mean=True      # average weight ~ 1.0\n",
    "    )\n",
    "\n",
    "\n",
    "    df_cosine, X_cosine, part, clusters_cosine, metrics_cosine = clustering_final(\n",
    "        df_gene,\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,\n",
    "        pca_or_not=False,\n",
    "        n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "        metric='cosine',          # 'euclidean' or 'cosine'\n",
    "        transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=0.8,\n",
    "        seed=42,\n",
    "        pos_weights=weights_pos,    # <-- emphasize central bins\n",
    "        weight_stage='pre_pca'\n",
    "\n",
    "    )\n",
    "\n",
    "    partition_cosine = np.asarray(part.membership, dtype=int)\n",
    "\n",
    "    \n",
    "    read_dict_cosine = dict_id_cluster_color(df_cosine, clusters_cosine, colours)\n",
    "    df_dict_cosine = dict_to_df(read_dict_cosine)\n",
    "    df_test_cosine= merge(df_proc, df_dict_cosine)\n",
    "\n",
    "    profiles_df, coverage_df, meta_df, positions = compute_gene_centroids(\n",
    "    df_reads=df_gene,        # reads × bins methylation matrix\n",
    "    df_map=df_dict_cosine,        # mapping of readid → cluster + color\n",
    "    gene_tss= gene,\n",
    "    extra_meta_cols=['gene_tss', 'group', 'cluster']  # add other non-bin columns here if present\n",
    ")\n",
    "    \n",
    "    # Build weights AFTER columns are coerced/sorted and intersection computed\n",
    "    Gc = _coerce_sort(profiles_df)\n",
    "    Pc = _coerce_sort(profiles_df_bulk_binned)\n",
    "    common = np.intersect1d(Gc.columns.values, Pc.columns.values)\n",
    "\n",
    "    weights_pos = build_positional_weights(\n",
    "    columns=common,      # use the intersection, not P_df.columns\n",
    "    window_bp=400,\n",
    "    center=0,\n",
    "    mode='gaussian',\n",
    "    inside_weight=1.0,\n",
    "    outside_weight=0.2,\n",
    "    normalize_mean=True\n",
    ")\n",
    "    assign_weighted_df, S, D = assign_gene_clusters_to_consensus(\n",
    "    G=Gc,\n",
    "    meta=meta_df,\n",
    "    P=Pc,\n",
    "    method='cosine',\n",
    "    center_rows=True,            # keep raw levels; set True for pattern-only\n",
    "    weights=weights_pos,          # emphasize +/- 500 bp region\n",
    "    min_overlap=20,               # ensure enough shared bins\n",
    "    min_similarity=0.5,           # allow 'unassigned' if below threshold\n",
    "    allow_unassigned=True,\n",
    "    capacity_per_type=1\n",
    ")\n",
    "\n",
    "    meta_for_assign_weighted = meta_df[['gene_tss', 'cluster_id', 'n_reads']].rename(columns={'n_reads': 'size'})\n",
    "    \n",
    "    fig, ax = plot_gene_mapping_heatmap(\n",
    "        assign_df=assign_weighted_df,\n",
    "        S=S,\n",
    "        meta=meta_for_assign_weighted,\n",
    "        P=Pc,\n",
    "        gene_id= gene,\n",
    "        sort_rows=False\n",
    "    )\n",
    "\n",
    "    bulk_color_map = {int(row['cluster_id']): row['cluster_color']\n",
    "                     for _, row in meta_bulk_df.iterrows()}  # build from bulk meta\n",
    "    \n",
    "    meta_colored = recolor_meta_by_bulk(assign_weighted_df, meta_df, bulk_color_map, gene_id= gene)\n",
    "\n",
    "    # print(meta_colored)\n",
    "\n",
    "    plot_centroids_with_shading(\n",
    "        profiles_df,\n",
    "        positions,\n",
    "        meta_colored,\n",
    "        coverage_df,\n",
    "        hex_colors,\n",
    "        smooth_sigma = 0,\n",
    "        title= gene + ' Average DNA Methylation Profiles per Cluster - reassigned colors - weighted clustering - weigthed gausian assignment',\n",
    "        missingness_threshold=0.5,\n",
    "        proportional_height=False,\n",
    "    )\n",
    "\n",
    "    print(assign_weighted_df['similarity'].mean())\n",
    "    sim.append(assign_weighted_df['similarity'].mean())\n",
    "\n",
    "print(np.mean(sim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WEIGHTED CLUSTERING + WEIGHTED BOX ASSIGNMENT LOOP OVER ALL GENES\n",
    "P_array = profiles_df_bulk_binned.to_numpy(float)\n",
    "sim=[]\n",
    "for i in range(len(gene_df)):\n",
    "    gene = gene_names[i]\n",
    "    df_gene = gene_df[i]\n",
    "\n",
    "    weights_pos = build_positional_weights(\n",
    "        columns=df_gene.columns,\n",
    "        window_bp=400,\n",
    "        center=0,\n",
    "        mode='gaussian',\n",
    "        inside_weight=1.0,\n",
    "        outside_weight=0.2,\n",
    "        sigma_bp=None,           # default window_bp/2\n",
    "        normalize_mean=True      # average weight ~ 1.0\n",
    "    )\n",
    "\n",
    "\n",
    "    df_cosine, X_cosine, part, clusters_cosine, metrics_cosine = clustering_final(\n",
    "        df_gene,\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,\n",
    "        pca_or_not=False,\n",
    "        n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "        metric='cosine',          # 'euclidean' or 'cosine'\n",
    "        transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=0.8,\n",
    "        seed=42,\n",
    "        pos_weights=weights_pos,    # <-- emphasize central bins\n",
    "        weight_stage='pre_pca'\n",
    "\n",
    "    )\n",
    "\n",
    "    partition_cosine = np.asarray(part.membership, dtype=int)\n",
    "\n",
    "    \n",
    "    read_dict_cosine = dict_id_cluster_color(df_cosine, clusters_cosine, colours)\n",
    "    df_dict_cosine = dict_to_df(read_dict_cosine)\n",
    "    df_test_cosine= merge(df_proc, df_dict_cosine)\n",
    "\n",
    "    profiles_df, coverage_df, meta_df, positions = compute_gene_centroids(\n",
    "    df_reads=df_gene,        # reads × bins methylation matrix\n",
    "    df_map=df_dict_cosine,        # mapping of readid → cluster + color\n",
    "    gene_tss= gene,\n",
    "    extra_meta_cols=['gene_tss', 'group', 'cluster']  # add other non-bin columns here if present\n",
    ")\n",
    "    \n",
    "    # Build weights AFTER columns are coerced/sorted and intersection computed\n",
    "    Gc = _coerce_sort(profiles_df)\n",
    "    Pc = _coerce_sort(profiles_df_bulk_binned)\n",
    "    common = np.intersect1d(Gc.columns.values, Pc.columns.values)\n",
    "\n",
    "    weights_pos = build_positional_weights(\n",
    "    columns=common,      # use the intersection, not P_df.columns\n",
    "    window_bp=400,\n",
    "    center=0,\n",
    "    mode='box',\n",
    "    inside_weight=1.0,\n",
    "    outside_weight=0.5,\n",
    "    normalize_mean=True\n",
    ")\n",
    "    assign_weighted_df, S, D = assign_gene_clusters_to_consensus(\n",
    "    G=Gc,\n",
    "    meta=meta_df,\n",
    "    P=Pc,\n",
    "    method='cosine',\n",
    "    center_rows=True,            # keep raw levels; set True for pattern-only\n",
    "    weights=weights_pos,          # emphasize +/- 500 bp region\n",
    "    min_overlap=20,               # ensure enough shared bins\n",
    "    min_similarity=0.5,           # allow 'unassigned' if below threshold\n",
    "    allow_unassigned=True,\n",
    "    capacity_per_type=1\n",
    ")\n",
    "\n",
    "    meta_for_assign_weighted = meta_df[['gene_tss', 'cluster_id', 'n_reads']].rename(columns={'n_reads': 'size'})\n",
    "    \n",
    "    fig, ax = plot_gene_mapping_heatmap(\n",
    "        assign_df=assign_weighted_df,\n",
    "        S=S,\n",
    "        meta=meta_for_assign_weighted,\n",
    "        P=Pc,\n",
    "        gene_id= gene,\n",
    "        sort_rows=False\n",
    "    )\n",
    "\n",
    "    bulk_color_map = {int(row['cluster_id']): row['cluster_color']\n",
    "                     for _, row in meta_bulk_df.iterrows()}  # build from bulk meta\n",
    "    \n",
    "    meta_colored = recolor_meta_by_bulk(assign_weighted_df, meta_df, bulk_color_map, gene_id= gene)\n",
    "\n",
    "    # print(meta_colored)\n",
    "\n",
    "    plot_centroids_with_shading(\n",
    "        profiles_df,\n",
    "        positions,\n",
    "        meta_colored,\n",
    "        coverage_df,\n",
    "        hex_colors,\n",
    "        smooth_sigma = 0,\n",
    "        title= gene + ' Average DNA Methylation Profiles per Cluster - reassigned colors - weighted clustering - weigthed box assignment',\n",
    "        missingness_threshold=0.5,\n",
    "        proportional_height=False,\n",
    "    )\n",
    "\n",
    "    print( assign_weighted_df['similarity'].mean())\n",
    "    sim.append(assign_weighted_df['similarity'].mean())\n",
    "\n",
    "print(np.mean(sim))\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline configurations\n",
    "configs = [\n",
    "    # --- PCA + Euclidean (no scaling) ---\n",
    "    dict(\n",
    "        name='euclidean',\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,\n",
    "        pca_or_not=True,\n",
    "        n_pcs=None,  # keep 95% variance\n",
    "        metric='euclidean',\n",
    "        transform='arcsine',  # can also use 'arcsine' or 'none'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=1.0,\n",
    "        seed=42\n",
    "    ),\n",
    "\n",
    "    # --- No PCA + Cosine (shape-based) ---\n",
    "    dict(\n",
    "        name='cosine',\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,  # keep raw 0..1; cosine similarity handles scale\n",
    "        pca_or_not=False,\n",
    "        n_pcs=None,\n",
    "        metric='cosine',\n",
    "        transform='arcsine',  # same transform for fairness\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=1.0,\n",
    "        seed=42\n",
    "    ),\n",
    "\n",
    "    # --- No PCA + Cosine + Positional Weights ---\n",
    "    dict(\n",
    "        name='cosine_weighted',\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,\n",
    "        pca_or_not=False,\n",
    "        n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "        metric='cosine',          # 'euclidean' or 'cosine'\n",
    "        transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=0.8,\n",
    "        seed=42,\n",
    "        pos_weights= build_positional_weights(\n",
    "            columns=df_gene.columns,\n",
    "            window_bp=400,\n",
    "            center=0,\n",
    "            mode='gaussian',\n",
    "            inside_weight=1.0,\n",
    "            outside_weight=0.2,\n",
    "            sigma_bp=None,           # default window_bp/2\n",
    "            normalize_mean=True      # average weight ~ 1.0\n",
    "        ),\n",
    "        weight_stage='post_pca'\n",
    "    )\n",
    "\n",
    "]\n",
    "\n",
    "# Example input dictionary of gene-level dataframes\n",
    "# e.g. genes_dict = {'GENE1': df_gene1, 'GENE2': df_gene2, ...}\n",
    "\n",
    "# Run the clustering pipelines\n",
    "results_df, outputs = run_pipelines_on_genes(gene_names, gene_df, configs)\n",
    "\n",
    "print(results_df['pipeline'].value_counts())\n",
    "\n",
    "for m in ['silhouette','calinski_harabasz','davies_bouldin','leiden_quality','modularity','n_clusters']: \n",
    "    if m in results_df.columns:\n",
    "        print(m, results_df.pivot_table(index='gene', columns='pipeline', values=m, aggfunc='first').isna().all())\n",
    "# Plot violin + scatter comparison of clustering metrics\n",
    "# figs = plot_violin_scatter(results_df)\n",
    "\n",
    "results_df.head(20)\n",
    "\n",
    "fig, axes = plot_compare_pipelines_grid(results_df,\n",
    "                                        pipelines_order=('euclidean', 'cosine','cosine_weighted'),\n",
    "                                        metrics=('silhouette','calinski_harabasz','davies_bouldin','leiden_quality','modularity','n_clusters'),\n",
    "                                        kind='violin', # or 'box' \n",
    "                                        show_points=True,\n",
    "                                        connect_pairs=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Compute and plot multi-metric silhouette scores for your existing results ===\n",
    "# Assumes you already ran:\n",
    "#   results_df, outputs = run_pipelines_on_genes(gene_names, gene_df, configs)\n",
    "# and that outputs[gene][pipeline] contains keys 'X_pca' and 'clusters'\n",
    "\n",
    "# 1) Build the embedding dict (gene, pipeline) -> {X, labels, metric}\n",
    "metric_map = {\n",
    "    'euclidean': 'euclidean',\n",
    "    'cosine': 'cosine',\n",
    "    'correlation': 'correlation'\n",
    "}\n",
    "embed_dict = {}\n",
    "for gene in gene_names:\n",
    "    if gene not in outputs:\n",
    "        continue\n",
    "    for cfg in configs:\n",
    "        pipeline = cfg['name']  # 'euclidean' or 'cosine'\n",
    "        if pipeline not in outputs[gene]:\n",
    "            continue\n",
    "        run = outputs[gene][pipeline]\n",
    "        if 'X_pca' not in run or 'clusters' not in run:\n",
    "            continue\n",
    "        embed_dict[(gene, pipeline)] = {\n",
    "            'X': run['X_pca'],\n",
    "            'labels': run['clusters'],\n",
    "            'metric': metric_map.get(pipeline, cfg.get('metric', 'euclidean'))\n",
    "        }\n",
    "\n",
    "# 2) Add extra silhouette columns (silhouette_cosine, silhouette_correlation, silhouette_euclidean)\n",
    "results_with_sil = add_silhouette_columns(results_df, embed_dict)\n",
    "\n",
    "# 3A) One plot per metric (auto-includes all columns named 'silhouette_*')\n",
    "figs_dict = plot_violin_scatter(results_with_sil)\n",
    "# Save (optional)\n",
    "# for metric_name, fig in figs_dict.items():\n",
    "#     fig.savefig(f\"violin_{metric_name}.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# 3B) One grid figure with all metrics (base + all silhouette_* columns)\n",
    "fig, axes = plot_compare_pipelines_grid(\n",
    "    results_df=results_with_sil,\n",
    "    pipelines_order=('euclidean', 'cosine', 'cosine_weighted'),\n",
    "    metrics=('calinski_harabasz', 'davies_bouldin', 'leiden_quality', 'modularity', 'n_clusters'),\n",
    "    kind='violin',\n",
    "    show_points=True,\n",
    "    connect_pairs=True)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# If you are using your older plot_compare_pipelines_grid signature (without\n",
    "# include_silhouettes), explicitly pass the silhouette_* columns you want:\n",
    "# -------------------------------------------------------------------------\n",
    "# sil_cols = [c for c in results_with_sil.columns if c.startswith('silhouette_')]\n",
    "# fig, axes = plot_compare_pipelines_grid(\n",
    "#     results_df=results_with_sil,\n",
    "#     pipelines_order=('euclidean', 'cosine'),\n",
    "#     metrics=tuple(['calinski_harabasz','davies_bouldin','leiden_quality','modularity','n_clusters'] + sil_cols),\n",
    "#     kind='violin',\n",
    "#     show_points=True,\n",
    "#     connect_pairs=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_first = (\n",
    "    df_filtered\n",
    "    .swaplevel('gene_tss', 'group')      # put 'group' as the outer level\n",
    "    .sort_index()                    # optional: sort by the new index\n",
    "    #.reset_index(level='gene_tss')       # move 'gene' from index to a column (metadata)\n",
    ")\n",
    "\n",
    "df_group_first.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names, group_df = get_groups_df_list(df_group_first)\n",
    "group_df[0]\n",
    "group_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names_group, gene_df_group = get_genes_list(group_df[0])\n",
    "gene_df_group[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(group_df)):\n",
    "    gene_names_group, gene_df_group = get_genes_list(group_df[i])\n",
    "    for k in range(len(gene_df_group)):\n",
    "        gene= gene_names_group[k]\n",
    "        df_group = gene_df_group[k]\n",
    "        df_group, X_group, partition_group, clusters_group, metrics_group = clustering_final(\n",
    "                df_group,\n",
    "                n_neighbors=10,\n",
    "                nan_threshold=0.7,\n",
    "                nan_method='drop',\n",
    "                scaling=False,\n",
    "                pca_or_not=True,\n",
    "                n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "                metric='euclidean',          # 'euclidean' or 'cosine' \n",
    "                transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "                kernel_type='laplacian',\n",
    "                leiden_resolution=1.1,\n",
    "                seed=42\n",
    "            )\n",
    "\n",
    "        # embedding_group, fig_group = plot_umap(\n",
    "        #         X_group,\n",
    "        #         clusters_group,\n",
    "        #         n_neighbors=25,\n",
    "        #         min_dist=0.1,\n",
    "        #         metric='euclidean',      \n",
    "        #         transform=None,          # None | 'logit' | 'arcsine' (use only if X are raw proportions)\n",
    "        #         n_pcs=None,              # set if X are raw features; None if X are already PCs\n",
    "        #         standardize=False,       # True if using raw features without PCA\n",
    "        #         seed=42,\n",
    "        #         palette=hex_colors,            # optional list/array or matplotlib colormap name\n",
    "        #         title=\"ALL FILTERED GENES PCA + Euclidean + logit + Laplacian\",\n",
    "        #         gene='ALL GENES'\n",
    "        #     )\n",
    "\n",
    "        read_dict_group = dict_id_cluster_color(df_group, clusters_group, hex_colors)\n",
    "\n",
    "        df_dict_group = dict_to_df(read_dict_group)\n",
    "        df_test_group= merge(df_proc, df_dict_group)\n",
    "\n",
    "        profiles_df_group, coverage_df_group, meta_df_group, positions_group= compute_gene_centroids(\n",
    "                                                                            df_group,\n",
    "                                                                            df_dict_group,\n",
    "                                                                            group= group_names[i],\n",
    "                                                                        )\n",
    "\n",
    "\n",
    "        plot_centroids_with_shading(\n",
    "            profiles_df_group,\n",
    "            positions_group,\n",
    "            meta_df_group,\n",
    "            coverage_df_group,\n",
    "            hex_colors,\n",
    "            smooth_sigma = 0,\n",
    "            title='Average DNA Methylation Profiles per Cluster - GROUP: ' + group_names[i] + gene,\n",
    "            missingness_threshold=0.5,\n",
    "        )\n",
    "\n",
    "    # Long format for plotting\n",
    "        df_test_plot_group = preprocess_long_for_plot(df_test_group,\n",
    "                                                                include_locus_cluster=True,\n",
    "                                                                filter_outliers= True,\n",
    "                                                                max_span_bp=2000,     #i'm letting the filtering be based on the span_quantile\n",
    "                                                                #   span_quantile=0.999,\n",
    "                                                                require_center_inside=True,\n",
    "                                                                min_cpg=1,\n",
    "                                                                cpg_window_bp=5000\n",
    "                                                                )\n",
    "         # Plot\n",
    "        plot_reads_long(\n",
    "                df_test_plot_group,\n",
    "                # filters={\n",
    "                #     # \"gene_tss\": gene, \n",
    "                #     'group':['BT474_mV_high_Untreated',\n",
    "                #     'BT474_mV_low_Untreated',\n",
    "                #     'BT474_mV_Untreated_Unsorted']},\n",
    "                # facet_by='group',\n",
    "                color_by=\"locus_cluster\",\n",
    "                gene='all genes',\n",
    "                hex_colors=hex_colors\n",
    "            )\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_df_group.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_group.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_centroids_with_shading(\n",
    "    profiles_df_group,\n",
    "    positions_group,\n",
    "    meta_df_group,\n",
    "    coverage_df_group,\n",
    "    hex_colors,\n",
    "    smooth_sigma = 0,\n",
    "    title='Average DNA Methylation Profiles per Cluster',\n",
    "    missingness_threshold=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_c, X_filtered_c, partition_filtered_c, clusters_filtered_c, metrics_filtered_c = clustering_final(\n",
    "        df_filtered,\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,\n",
    "        pca_or_not=True,\n",
    "        n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "        metric='cosine',          # 'euclidean' or 'cosine' \n",
    "        transform='none',            # 'none', 'logit', or 'arcsine'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=1.1,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "# embedding_filtered_c, fig_filtered_c = plot_umap(\n",
    "#         X_filtered_c,\n",
    "#         clusters_filtered_c,\n",
    "#         n_neighbors=25,\n",
    "#         min_dist=0.1,\n",
    "#         metric='cosine',      \n",
    "#         transform=None,          # None | 'logit' | 'arcsine' (use only if X are raw proportions)\n",
    "#         n_pcs=None,              # set if X are raw features; None if X are already PCs\n",
    "#         standardize=False,       # True if using raw features without PCA\n",
    "#         seed=42,\n",
    "#         palette=hex_colors,            # optional list/array or matplotlib colormap name\n",
    "#         title=\"ALL FILTERED GENES Cosine\",\n",
    "#         gene='ALL GENES'\n",
    "#     )\n",
    "\n",
    "# print(metrics_filtered_c)\n",
    "\n",
    "# multi_sil_filtered_c= silhouettes_multi(X_filtered_c, clusters_filtered_c, metric_main='cosine', extra_metrics=['euclidean', 'correlation', 'jaccard'])\n",
    "\n",
    "# print(f\"Silhouette (Cosine): {metrics_filtered_c['silhouette']:.3f}\")\n",
    "# print(f\"Silhouette (Cosine) - Euclidean: {multi_sil_filtered_c['silhouette_euclidean']:.3f}\")\n",
    "# print(f\"Silhouette (Cosine) - Correlation: {multi_sil_filtered_c['silhouette_correlation']:.3f}\")\n",
    "# print(f\"Silhouette (Cosine) - Jaccard: {multi_sil_filtered_c['silhouette_jaccard']:.3f}\")\n",
    "\n",
    "\n",
    "read_dict_filtered_c = dict_id_cluster_color(df_filtered_c, clusters_filtered_c, hex_colors)\n",
    "\n",
    "df_dict_filtered_c = dict_to_df(read_dict_filtered_c)\n",
    "df_test_filtered_c= merge(df_proc, df_dict_filtered_c)\n",
    "\n",
    "# Long format for plotting\n",
    "df_test_plot_filtered_c = preprocess_long_for_plot(df_test_filtered_c,\n",
    "                                                          include_locus_cluster=True,\n",
    "                                                          filter_outliers= True,\n",
    "                                                          max_span_bp=None,     #i'm letting the filtering be based on the span_quantile\n",
    "                                                          span_quantile=0.99,\n",
    "                                                          require_center_inside=True,\n",
    "                                                          min_cpg=1,\n",
    "                                                          cpg_window_bp=5000\n",
    "                                                          )\n",
    "\n",
    "    # Plot\n",
    "\n",
    "plot_reads_long(\n",
    "        df_test_plot_filtered_c,\n",
    "        filters={\n",
    "            # \"gene_tss\": gene, \n",
    "            'group':['BT474_mV_high_Untreated',\n",
    "            'BT474_mV_low_Untreated',\n",
    "            'BT474_mV_Untreated_Unsorted']},\n",
    "        # facet_by='group',\n",
    "        color_by=\"locus_cluster\",\n",
    "        gene='all genes - cosine',\n",
    "        hex_colors=hex_colors,\n",
    "        figsize= (12,10)\n",
    "    )\n",
    "\n",
    "# plot_single_molecule_occupancy_rlike(\n",
    "#     df=df_test_plot_filtered_c,\n",
    "#     # cluster_colors=cluster_to_color,\n",
    "#     xlim=(-1100, 1100),\n",
    "#     stripe_lw=1.5,\n",
    "#     point_size=0.6,\n",
    "#     figsize_cm=(12, 10),\n",
    "#     dpi=300,\n",
    "    \n",
    "# )\n",
    "\n",
    "df_only_interesting_groups_filtered_c = df_filtered_c[df_filtered_c.index.get_level_values('group').isin([\n",
    "        'BT474_mV_high_Untreated',\n",
    "        'BT474_mV_low_Untreated',\n",
    "        'BT474_mV_Untreated_Unsorted'\n",
    "    ])]\n",
    "\n",
    "# df_only_interesting_groups_filtered_c = merge(df_only_interesting_groups_filtered_c, df_dict_filtered_c)\n",
    "# clusters_of_interest_filtered_c = df_only_interesting_groups_filtered_c['locus_cluster'].tolist() \n",
    "# summary(df_only_interesting_groups_filtered_c, clusters_of_interest_filtered_c, gene='all genes - cosine')\n",
    "\n",
    "profiles_df_filtered_c, coverage_df_filtered_c, meta_df_filtered_c, positions_filtered_c = compute_gene_centroids(\n",
    "                                                                        df_filtered_c,\n",
    "                                                                        df_dict_filtered_c,\n",
    "                                                                        gene_tss=gene,\n",
    "                                                                    )\n",
    "\n",
    "plot_centroids_with_shading(\n",
    "        profiles_df_filtered_c,\n",
    "        positions_filtered_c,\n",
    "        meta_df_filtered_c,\n",
    "        coverage_df_filtered_c,\n",
    "        hex_colors,\n",
    "        smooth_sigma = 0,\n",
    "        title= gene + ' : Average DNA Methylation Profiles per Cluster - COSINE ',\n",
    "        missingness_threshold=0.5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_color = {int(v[\"cluster\"]): v[\"color\"] for v in read_dict_filtered_c.values()}\n",
    "\n",
    "df_test_plot_filtered_c['order']= df_test_plot_filtered_c['cluster']\n",
    "# df_test_plot_filtered_c.head()\n",
    "cluster_to_color "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_single_molecule_occupancy(\n",
    "#     df=df_test_plot_filtered_c,\n",
    "#     cluster_colors=cluster_to_color,\n",
    "#     xlim=(-1000, 1000),\n",
    "#     point_size=2,\n",
    "#     figsize_cm=(15, 9),\n",
    "#     dpi=280\n",
    "# )\n",
    "plot_single_molecule_occupancy_rlike(\n",
    "    df=df_test_plot_filtered_c,\n",
    "    cluster_colors=cluster_to_color,\n",
    "    xlim=(-1100, 1100),\n",
    "    stripe_lw=1.5,\n",
    "    point_size=0.6,\n",
    "    figsize_cm=(12, 10),\n",
    "    dpi=300,\n",
    "    n_clusters=len(cluster_to_color)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine, X_cosine, partition_cosine, clusters_cosine, metrics_cosine = clustering_final(\n",
    "        gene_df[78],\n",
    "        n_neighbors=15,\n",
    "        nan_threshold=0.7,\n",
    "        nan_method='drop',\n",
    "        scaling=False,\n",
    "        pca_or_not=False,\n",
    "        n_pcs=None,           # None = no PCA; int for #PCs; float in (0,1) for variance ratio\n",
    "        metric='cosine',          # 'euclidean' or 'cosine'\n",
    "        transform='arcsine',            # 'none', 'logit', or 'arcsine'\n",
    "        kernel_type='laplacian',\n",
    "        leiden_resolution=0.8,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "embedding_cosine, fig_cosine = plot_umap(\n",
    "        X_cosine,\n",
    "        clusters_cosine,\n",
    "        n_neighbors=25,\n",
    "        min_dist=0.1,\n",
    "        metric='cosine',      # for Pipeline 2, use 'euclidean'\n",
    "        transform=None,          # None | 'logit' | 'arcsine' (use only if X are raw proportions)\n",
    "        n_pcs=None,              # set if X are raw features; None if X are already PCs\n",
    "        standardize=False,       # True if using raw features without PCA\n",
    "        seed=42,\n",
    "        palette=hex_colors,            # optional list/array or matplotlib colormap name\n",
    "        title=\"NO PCA + cosine + laplacian\",\n",
    "        gene= gene_names[78]\n",
    "    )\n",
    "\n",
    "# print(metrics_cosine)\n",
    "\n",
    "# multi_sil_cosine= silhouettes_multi(X_cosine, clusters_cosine, metric_main='cosine', extra_metrics=['euclidean', 'correlation', 'jaccard'])\n",
    "\n",
    "# print(f\"Silhouette (Cosine): {metrics_cosine['silhouette']:.3f}\")\n",
    "# print(f\"Silhouette (Cosine) - Euclidean: {multi_sil_cosine['silhouette_euclidean']:.3f}\")\n",
    "# print(f\"Silhouette (Cosine) - Correlation: {multi_sil_cosine['silhouette_correlation']:.3f}\")\n",
    "# print(f\"Silhouette (Cosine) - Jaccard: {multi_sil_cosine['silhouette_jaccard']:.3f}\")\n",
    "\n",
    "\n",
    "read_dict_cosine = dict_id_cluster_color(df_cosine, clusters_cosine, hex_colors)\n",
    "\n",
    "df_dict_cosine = dict_to_df(read_dict_cosine)\n",
    "df_test_cosine= merge(df_proc, df_dict_cosine)\n",
    "\n",
    "profiles_df, coverage_df, meta_df, positions = compute_gene_centroids(\n",
    "    df_reads=gene_df[78],        # reads × bins methylation matrix\n",
    "    df_map=df_dict_cosine,        # mapping of readid → cluster + color\n",
    "    gene_tss= gene_names[78],\n",
    "    extra_meta_cols=['gene_tss', 'group', 'cluster']  # add other non-bin columns here if present\n",
    ")\n",
    "\n",
    "plot_centroids_with_shading(\n",
    "    profiles_df,\n",
    "    positions,\n",
    "    meta_df,\n",
    "    coverage_df,\n",
    "    hex_colors,\n",
    "    smooth_sigma = 0,\n",
    "    title='Average DNA Methylation Profiles per Cluster',\n",
    "    missingness_threshold=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_df_bulk_to_filtered, S, D = assign_gene_clusters_to_consensus(\n",
    "    G=profiles_df_filtered_c,               # DataFrame (rows = gene clusters, cols = common positions)\n",
    "    meta=meta_df_filtered_c,         # aligned to G rows\n",
    "    P=profiles_df_bulk_binned,               # DataFrame (rows = bulk clusters, cols = common positions)\n",
    "    method='cosine',\n",
    "    center_rows=True,\n",
    "    # weights=weights,  # optional pd.Series indexed by common positions\n",
    "    min_overlap=40,\n",
    "    min_similarity=0,\n",
    "    allow_unassigned=True,\n",
    "    capacity_per_type=1,\n",
    ")\n",
    "\n",
    "meta_for_assign_bulk_to_filtered = meta_df_filtered_c[['gene_tss', 'cluster_id', 'n_reads']].rename(columns={'n_reads': 'size'})\n",
    "\n",
    "assign_df_bulk_to_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_gene_mapping_heatmap(\n",
    "    assign_df=assign_df_bulk_to_filtered,\n",
    "    S=S,\n",
    "    meta=meta_for_assign_bulk_to_filtered,\n",
    "    P=profiles_df_bulk_binned,\n",
    "    gene_id='SETD1A_30958295_30958295',\n",
    "    sort_rows=False\n",
    ")\n",
    "\n",
    "# 3) Assignment summary across genes\n",
    "fig2, ax2 = plot_assignment_summary(assign_df_bulk_to_filtered)\n",
    "\n",
    "# 4) Recolor meta for plotting centroids\n",
    "bulk_color_map = {cons_id: '#hexcolor' for cons_id in P_df.index}  # build from bulk meta\n",
    "meta_colored = recolor_meta_by_bulk(assign_df_bulk_to_filtered, meta_df_filtered_c, bulk_color_map, gene_id=gene)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_df_bulk_to_filtered, S, D = assign_gene_clusters_to_consensus(\n",
    "    G=profiles_df_filtered_c,               # DataFrame (rows = gene clusters, cols = common positions)\n",
    "    meta=meta_df_filtered_c,         # aligned to G rows\n",
    "    P=profiles_df_bulk_binned,               # DataFrame (rows = bulk clusters, cols = common positions)\n",
    "    method='cosine',\n",
    "    center_rows=False,\n",
    "    # weights=weights,  # optional pd.Series indexed by common positions\n",
    "    min_overlap=40,\n",
    "    min_similarity=0,\n",
    "    allow_unassigned=True,\n",
    "    capacity_per_type=1,\n",
    ")\n",
    "\n",
    "meta_for_assign_bulk_to_filtered = meta_df_filtered_c[['gene_tss', 'cluster_id', 'n_reads']].rename(columns={'n_reads': 'size'})\n",
    "\n",
    "assign_df_bulk_to_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_gene_mapping_heatmap(\n",
    "    assign_df=assign_df_bulk_to_filtered,\n",
    "    S=S,\n",
    "    meta=meta_for_assign_bulk_to_filtered,\n",
    "    P=profiles_df_bulk_binned,\n",
    "    gene_id='SETD1A_30958295_30958295',\n",
    "    sort_rows=False\n",
    ")\n",
    "\n",
    "# 3) Assignment summary across genes\n",
    "fig2, ax2 = plot_assignment_summary(assign_df_bulk_to_filtered)\n",
    "\n",
    "# 4) Recolor meta for plotting centroids\n",
    "bulk_color_map = {cons_id: '#hexcolor' for cons_id in P_df.index}  # build from bulk meta\n",
    "meta_colored = recolor_meta_by_bulk(assign_df_bulk_to_filtered, meta_df_filtered_c, bulk_color_map, gene_id=gene)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
